# 索引

![](image/Pasted%20image%2020250218152217.png)

# 服务注册和发现

## 介绍

你设想这样一个场景，你的服务部署在不同的机房、不
同的机器上，监听不同的端口。现在你的客户端收到了一个请求，要发送给服务端，那么你的客户端怎么知道哪些服务端能够处理这个请求呢

举一个例子，你去一个陌生的城市出差，下班了想去吃个火锅，还得是重庆火锅。那么你怎么
知道这个城市哪里有重庆火锅？
你可能会说，我在 App 里面搜一下。那么 App 又怎么知道这里有一家重庆火锅店呢？你继续
说，这肯定是商家去这个 App 注册过了呀！对，服务注册与发现模型就是这样。你扮演了客
户端的角色，火锅店扮演了服务端的角色，而 App 则是扮演了我们常说的注册中心的角色。

那么我们现在就容易理解基本的服务注册与发现模型了

1. 服务端启动的时候，需要往注册中心里注册自身的信息，主要是定位信息
2. 注册成功之后，注册中心和服务端要保持心跳
3. 客户端第一次发起对某个服务的调用之前，要先找注册中心获得所有可用服务节点列表，随后客户端会在本地缓存每个服务对应的可用节点列表
4. 客户端和注册中心要保持心跳和数据同步，后续服务端有任何变动，注册中心都会通知客户端，客户端会更新本地的可用节点列表
5. 客户端发送请求
6. 服务端返回响应

![](image/Pasted%20image%2020250218152739.png)

我们还是用前面的例子来描述，一家门店准备关张不再营业了，那么它需要做一些什么？显然它需要告诉 App 自己不再营业了，那么你在平台上也就再也搜索不到它了，所以，服务端下线的过程可以总结为 4 步

1. 服务端通知注册中心自己准备下线了
2. 注册中心通知客户端某个服务端下线了
3. 客户端收到通知之后，新来的请求就不会再给该服务端发过去
4. 服务端等待一段时间之后，暂停服务并下线。


需要注意的是，服务端必须要等待一段时间才能下线。因为从它通知注册中心自己要下线，到客户端收到通知，是有一段延时的，这段延时就是服务端要等待的最小时间

如果你觉得这些步骤很复杂，那么我可以教你一个小技巧。你可以把整个模型看作是三角形，三个顶点分别是

- 客户端
- 注册中心
- 服务端

三角形的三条边分别是

- 客户端 - 注册中心
- 注册中心 - 服务端
- 客户端 - 服务端

而后面我们讨论的高可用方案，**无非就是仔细思考三角形的任何一个顶点，或者任何一条边出问题了该怎么办**

## 面试准备

在面试前，如果你们公司确实是使用了注册中心，那么你要弄清楚一些数据和信息

- 你们用了什么中间件作为注册中心以及该中间件的优缺点
- 确保自己在回答“你为什么用某个中间件作为注册中心”的时候，能够综合这些优缺点来回答
- 注册中心的集群规模
- 读写 QPS（每秒查询率）
- 机器性能，如 CPU 和内存大小
- 准备一个注册中心出故障之后你排查和后续优化的案例，在讨论使用注册中心的注意事项，或者遇到过什么 Bug 的时候可以用这个案例。

如果你所在的公司没有采用微服务架构，那么你可以在 ZooKeeper、Nacos 或者 etcd 里面选择一个大概学习一下它们的基本特性。在面试的时候你可以用它们来解释注册中心。这样就算你没接触过服务注册与发现，但是你对此也是有相当深入的理解的。

在面试过程中，你可以尝试从这些角度把话题引到服务注册与发现这个主题上

- **面试官问到了某一个可以作为注册中心的中间件**
	- 如果你用 ZooKeeper 作为注册中心，那么如果面试官问到了 ZooKeeper，你可以主动提起你把它作为了注册中心；如果面试官问了 etcd，那么你可以主动提起 etcd 虽好，但是你用的是 ZooKeeper。这个时候面试官很有可能会继续追问你，为什么最终选择 ZooKeeper 作为注册中心，这时候说一下它的优缺点就好了
- **面试官问了微服务高可用的问题**
	- 那么你可以把高可用的服务注册与发现作为保证整个微服务架构**高可用**的一个环节来叙述

### 基本思路

一般而言，在最开始的阶段，面试官会问你“你知道服务注册与发现吗？”或者“你知道注册中心吗？”等问题，其实都是希望你回答**服务注册与发现的基本模型**


那么你可以回答[为什么需要注册中心](#为什么需要)里面的服务上线和服务下线这两个流程的具体步骤，而后可以简单描述一下你所在公司的注册中心，也就是罗列一下你准备的那些数据和信息。基本内容说完之后，你可以先浅刷一个亮点，关键词是**注册数据**

- 在说第一个步骤的时候，我提到“主要是定位信息”。既然用到了关键词“主要”，那自然有不那么主要的数据。非主要数据取决于微服务框架的功能特性。例如常见的分组功能，就是依赖于服务端在注册的时候同时注册自己的分组信息

![](image/Pasted%20image%2020250218154914.png)

所以你可以用一个例子来解释，关键词是**分组**

- 服务端注册的数据除了定位信息是必需的以外，剩下需要什么数据都是根据微服务框架本身的功能和业务来设计的，比如说很多微服务框架支持分组功能，那么就可以让服务端在注册的时候同时注册自己的分组信息
- 比如说当前节点是 VIP 节点，那么客户端在收到 VIP 请求之后就会把请求发给 VIP 节点

这一段说完之后，你要稍微总结一下，引导面试官追问下去

- 服务注册与发现的整个模型比较简单，不过要在实践中做到高可用还是很不容易的

至于为什么不容易、怎么不容易你就等着面试官继续问。而**高可用**就是我们要刷的亮点

### 如何实现高可用

不出所料的话，面试官就可能追问：“服务注册与发现怎么保证高可用呢？”，那么你就可以回答三个点，高可用的服务注册与发现要围绕

- 注册服务端崩溃检测
- 客户端容错
- 注册中心选型

三个方面进行，也就是三角形的三个顶点

#### 服务端崩溃检测

在正常情况下，服务端下线都需要通知注册中心。那么万一服务端宕机了呢？比如说运维大哥不小心一脚把服务器电源线踢掉了，服务器直接停电了。在这种情况下，服务端是没办法通知注册中心的，注册中心自然也就不会通知客户端。那么客户端就会继续把请求发送给服务端，而这些请求显然都会失败

![](image/Pasted%20image%2020250218171238.png)

因此为了提高可用性，需要让注册中心尽快发现服务端已经崩溃了，而后通知客户端。所以问题的关键就在于**注册中心怎么判断服务端已经崩溃**。

你可能在上面这张图片里注意到了，服务端崩溃之后注册中心和服务端之间的心跳就无法继续保持了，所以你得出一个简单的结论

- **如果注册中心和服务端之间的心跳断了，就认为服务端已经崩溃了**

但是，如果注册中心和服务端之间的网络出现偶发性的抖动，那么心跳也会失败。此时服务端并没有真的崩溃，还活得好好的

![](image/Pasted%20image%2020250218171904.png)

显然，心跳断了则服务端崩溃的判断并不能成立。这时候你可能会想到能不能多发几次心跳呢？答案是可以，但是次数越多，心跳间隔越长，注册中心断定服务端已经崩溃的时间就越长。而时间越长，就有越多请求发送给服务端。万一这个时候服务端真的崩溃了，这些请求都会失败。所以这就陷入两难境地了。要么是误以为服务端崩溃，要么是误以为服务端还活着

那么怎么走出这个窘境呢？

- 一方面，注册中心在和服务端进行心跳的时候失败了，就要立刻通知客户端该服务端已经不可用了，那么客户端就不会再发请求过来
- 另外一方面，注册中心还要继续往服务端发心跳，如果只是偶发性的心跳失败，那么注册中心后面心跳是肯定能够连上的，这时候注册中心再通知客户端这个服务端是可用的。

![](image/Pasted%20image%2020250218190441.png)

![](image/Pasted%20image%2020250218190452.png)

不过注册中心并不是无限制发心跳直到连接上，而是发了一段时间之后发现心跳还是失败就不再发了，这意味着注册中心认定服务端彻底崩溃了。在彻底崩溃的场景下，注册中心不需要再次通知客户端，因为在之前注册中心就已经通知过了

所以关键词就是 **心跳**

- 影响到可用性的另一个关键点是**注册中心需要尽快发现服务端宕机**。在基本模型里面，如果服务端突然宕机，那么服务端是来不及通知注册中心的。所以注册中心需要有一种检测机制，判断服务端有没有崩溃。在服务端崩溃的情况下，要及时通知客户端，不然客户端就会继续把请求发送到已经崩溃的节点上。
- **这种检测就是利用心跳来进行的**。当注册中心发现和服务端的心跳失败了，那么它就应该认为服务端可能已经崩溃了，就立刻通知客户端停止使用该服务端。但是这种失败可能是偶发性的失败，比如说因为网络偶尔不稳定造成的。所以注册中心要继续保持心跳。如果几次心跳都失败了，那么就可以认为服务端已经彻底不可用了。但是如果心跳再次恢复了，那么注册中心就要再次告诉客户端这个服务端是可用的。

回答到这里，亮点已经有了，不过你还可以继续钓鱼，稍微升华一下。

- 实际上，在**所有有心跳机制的分布式系统里面判断节点是否崩溃都是一个棘手的问题**

	- 心跳失败了要不要继续重试
	- 是立刻重试还是间隔重试
	- 重试的话试几次

- 理论上来说，在心跳失败之后如果不进行重试就直接判定服务端崩溃，那么就难以处理偶发性网络不通的问题
- 而如果要重试，比如说在注册中心和服务端的模型里面，重试三次，而且重试间隔是十秒钟，那么注册中心确定服务端崩溃就需要三十秒。在这三十秒内，客户端估计有成千上万的请求尝试发到崩溃的服务端，结果都失败了。

这时候，面试官很自然地就会觉得不要搞重试间隔，而是直接发起连续几次重试，这时候你就要无情地击碎这种幻想。

- 如果不考虑重试间隔的话，就难以避开偶发性的失败。比如说注册中心和服务端之间网络抖动，那么第一次心跳失败之后，你立刻重试多半也是失败的，因为此时网络很可能还是不稳定。
- 所以比较好的策略是立刻重试几次，如果都失败了就再间隔一段时间继续重试。所有的重试机制实际上也是要谨慎考虑重试次数和重试间隔的，确保在业务可以接受的范围内重试成功。不过再怎么样，从服务端崩溃到客户端知道，中间总是存在一个时间误差的，这时候就需要客户端来做容错了。

这个回答里面，最后的一句话，就是为了引出下面这个亮点：**客户端容错**。

#### 客户端容错

客户端容错是指**尽量在注册中心或者服务端节点出现问题的时候，依旧保证请求能够发送到正确的服务端节点上**

在前一个亮点里面，你已经知道从服务端崩溃到客户端最终知道是有一段延时的。在这段延时内，客户端还是会把请求发送到已经崩溃的服务端节点上

![](image/Pasted%20image%2020250218213357.png)

所以你要紧接着前面刷的亮点继续回答，关键词是
**换节点**，也就是所谓的 **failover**

- 客户端容错第一个要考虑的是如果某个服务端节点崩溃了该怎么办
- 在服务端节点崩溃之后，到注册中心发现，再到客户端收到通知，是存在一段延时的，这个延时是能算出来的。在这段延时内，客户端发送请求给这个服务端节点都会失败
- 这个时候需要客户端来做一些容错。一般的策略是客户端在发现调不通之后，应该尝试换另外一个节点进行重试
- 如果客户端上的服务发现组件或者负载均衡器能够根据调用结果来做一些容错的话，那么它们应该要尝试将这个节点挪出可用节点列表，在短时间内不要再使用这个节点了。后面再考虑将这个节点挪回去

![](image/Pasted%20image%2020250218213712.png)

在上面那段话中，我留了两个口子

第一个是延时怎么计算，非常简单，你从图里面就能看出

- 最坏的情况下，延时等于服务端和注册中心心跳间隔加上注册中心通知客户端的时间。大多数时候，注册中心通知客户端都是很快的，在毫秒级以内。因此可以认为服务端和注册中心的心跳间隔就是这个延时

第二个点就是什么时候再将这个节点挪回可用列表，在上图中就是 A 什么时候会被重新放回可用列表

- 显然，如果注册中心最终发现服务端崩溃，然后通知了客户端，那么客户端就不用放回去了。等到注册中心发现服务端再次恢复了，那么注册中心会通知客户端，此时客户端更新可用节点列表就可以了

![](image/Pasted%20image%2020250218214106.png)

但是有一种情况是需要客户端主动检测的。这种情况就是服务端节点还活着，注册中心也还活着，唯独客户端和服务端之间的网络有问题，导致客户端调用不通

![](image/Pasted%20image%2020250218214139.png)

在这种情况下，类似于注册中心和服务端心跳失败，客户端也要朝着那个疑似崩溃的服务端节点继续发送心跳。如果心跳成功了，就将节点放回可用列表，如果连续几次心跳都没有成功，那么就不用放回去了，直接认为这个节点已经崩溃了

这个分析也适用于客户端和注册中心心跳失败的场景。很显然在这种情况下，客户端可以直接使用本地缓存的可用节点列表，而后如果调不通了则处理方式完全一样。但是不同的是，如果客户端长期连不上注册中心，那么客户端本身应该考虑整个退出。

#### 注册中心选型

注册中心选型类似于其他中间件选型，要考虑的因素非常多。比如说中间件成熟度、社区活跃度、性能等因素。相比之下，注册中心更加关注 CAP 中选 CP 还是选 AP 的问题

- C：Consistency，数据一致性
- A：Availability，服务可用性
- P：Partition-tolerance，分区容错性
- CAP 理论告诉我们，一个分布式系统不可能同时满足数据一致性、服务可用性和分区容错性这三个基本需求，最多只能同时满足其中的两个

简单来说，选择 CP 就是选了一致性和分区容错性，而选择 AP 就相当于选了可用性和分区容错性

看上去 P 分区容错性是肯定要选的，那么剩下的就是选 C（一致性） 还是选 A（可用性） 了。那么你要先理解在注册中心选型里面，一致性和可用性究竟哪个更加重要？标准答案是可用性，也就意味着 CP 和 AP 你应该选 AP。

前面我们讨论了客户端容错，那么显然在选择 AP 的情况下，客户端就可能拿到错误的可用节点列表。如果客户端将请求发到错误的可用节点上，就会出现错误，此时客户端自然可以执行容错，换一个可用节点重试

所以我们要抓住关键词**客户端容错**进行回答

- 在注册中心选型上，重要的是 CAP 原理中应该选择 AP
- 比如说 Eureka
- 又或者 Nacos 启用 AP 模式

万一你公司并没有使用 AP 模型的注册中心，比如说用了 CP 模型的 ZooKeeper，那么你就可以进一步解释，关键词是**体量小**

- 我司之所以用 ZooKeeper，主要是因为我司体量小，集群规模也不大，ZooKeeper 虽然不是 AP 的，但是在这种体量下也够用了
- 不过我也尝试在公司内部推动看能否换一个中间件，比如说用 Nacos 的 AP 模式

### 思路总结

最后，让我们来总结一下重点内容

我们主要解决的是**服务注册与发现的问题**。给出了基本的服务注册与发现模型，然后从

- **服务端崩溃检测**
- **客户端容错**
- **注册中心选型**

三个角度来保证了服务注册与发现的高可用。其中我提到了几个关键词

- 注册数据
- 分组
- 心跳
- 换节点
- 客户端容错
- 体量小

你可以从这几个关键词出发，根据自己的项目经验，梳理思路

最后我再提醒一下，如果你觉得服务注册与发现实在难以记忆，可以把整个模型想成是一个三角形，而解决高可用问题的关键就是这个三角形任何一条边出问题了该怎么办，我非常建议你画一画这个三角形，并且手写一下你能想到的各种容错措施

![](image/Pasted%20image%2020250218214952.png)

## 思考题

来思考 2 个问题

1. 我在客户端容错里提到这个分析也适用于注册中心崩溃，你能组织一下语言尝试回答 “如果注册中心崩溃，你的系统会怎样” 这个问题

- 如果出现注册中心崩溃，站在客户端的角度，会有两种情况

	1. 只有注册中心崩溃了
	2. 注册中心和所有服务端节点一起崩溃了

- 客户端需要确认是哪种情况，客户端需要继续向注册中心发送心跳，同时使用本地缓存的服务端节点列表，向服务端发送请求，确认是否出现无法访问的服务端节点，可以分为以下几种情况

	1. 向注册中心发送心跳失败，但是服务端仍可调用，此时因根据客户端容错策略使用本地缓存的服务端节点进行调用
	2. 向注册中心发送心跳失败，同时服务端不可调用，此时客户端需要使用本地缓存的服务端节点，确认是否所有服务端节点都不可用，如果都不可用，客户端停止向服务端发送请求，并保持向注册中心发送心跳，等待注册中心重新上线
	3. 还有一种情况是客户端还没缓存服务端节点列表，这时注册中心挂了，此时客户端无法获取到服务端节点的位置信息，只能保持向注册中心发送心跳 等待注册中心上线


2. 你可以再举出一个心跳频率、心跳重试机制对系统可用性影响的例子

	- 心跳频率过长，会增加系统判断故障的延迟
	- 如果心跳频率过短，又会增加系统负载和网络流量，造成系统资源的过度消耗
	- 需要在系统负载和实时性要求之间做权衡，选择合适的心跳频率。心跳重试机制，避免了偶发性的网络抖动造成的故障误判，但同时也变相增加了判断故障的延迟。重试次数、间隔设计不合理，同样会造成系统资源的过度消耗


# 负载均衡

负载均衡在微服务架构里也处于一个核心位置。一般我们在准备调用任何服务的时候，第一个
要解决的问题就是负载均衡该怎么做

负载均衡在微服务架构的面试中，也属于必面题目可惜的是，即便我们都知道负载均衡在面试中是必考点，但是在每一次面试的时候都还是难以刷出亮点。大多数的回答都仅仅是简单罗列一下负载均衡的算法，稍微有些亮点的则是讨论一下不同算法的优缺点。但是这并不能让你在面试官心里留下深刻印象

所以介绍一下负载均衡算法里面一些可以用于面试的微妙细节，同时给出一个本地缓存和负载均衡结合的案例，让你在面试的时候刷出亮点。下面我先来给你介绍微服务架构里面常见的负载均衡算法，让你先有一个最基本的理解。

## 介绍

负载均衡，本质上就是回答一个问题： **我该把请求发给哪个服务端** 理论上来说，你会希望把请求发给某个能够最快返回响应的客户端

![](image/Pasted%20image%2020250218221244.png)

这里你可能会觉得有些困惑，因为我们之前都听过

- 轮询
- 加权轮询
- 随机
- 加权随机
- 哈希
- 一致性哈希

这些负载均衡算法，但看上去它们并没有试图去判断哪个节点才是最合适的节点，这一类算法也叫做**静态负载均衡算法**

它们依靠的是统计学上的 “最合适” 。也就是说，如果请求都差不多，请求数量也足够多，那么它们能够挑选出比较合适的节点

还有一类算法，是**动态负载均衡算法**，或者说是**实时检测负载均衡算法**

这一类算法依赖于**实时判断所有候选节点的状态，并且从里面挑选出最合适的节点**。这一类算法包含

- 最少连接数
- 最少活跃请求数
- 最快响应时间等算法

## 轮询与加权轮询

轮询本身是一个非常简单的算法，用一句俗话讲，就是“排排坐，分果果”。也就是说，所有的候选节点轮流作为负载均衡的目标节点

![](image/Pasted%20image%2020250218222206.png)

你可能想到，每个节点的实际处理能力可能并不一样。于是就有了一个加权的版本，就是所谓的加权轮询。这个算法就不再是节点轮流，而是根据权重来轮流，比如说，如果一个节点的权重是另外一个节点的两倍，那么最终这个节点被选中的次数也会是另外一个节点的两倍

![](image/Pasted%20image%2020250218222215.png)

图中节点 1 的权重是其他两个节点的三倍，所以相应地被选中的机会也是三倍。在加权算法里面，有一个改进叫做平滑的加权轮询算法

你在图里也可以看出来，因为服务端节点 1 的权重是别的节点的三倍，所以如果你不做任何措施，那么会连续三次将请求发送到同一个节点。而这个平滑的加权轮询算法就是为了解决这个问题

每个节点会有两个权重，初始权重（weight）和当前权重（currrentWeight）。算法的过程稍微有点复杂，每一次挑选节点都执行这些步骤

- 对每一个节点，执行 currrentWeight = currrentWeight + weight
- 挑选最大 currrentWeight 的节点作为目标节点
- 将目标节点的 currrentWeight 修改为 currrentWeight= currrentWeight - sum(weight)。

那么简单理解就是，对于一个节点来说，每次被挑选之后，它的 currrentWeight 就会下降，那么下一次就不会选中它。

## 随机与加权随机

随机可以看作是随便挑选一个作为目标节点，加权随机则是利用不同的权重来设置选中的概率。权重越大，那么被选中的机会也就越大

你可以看到，轮询算法相比之下可控性更强。一般来说，在实践中

- 轮询和随机
- 加权轮询和加权随机

是可以互相替代的

![](image/Pasted%20image%2020250218222534.png)

## 哈希与一致性哈希

哈希算法比较简单，一般就是选取请求里面某几个参数来计算一个哈希值，然后除以节点数量取余。这个过程几乎和随机一样，区别就在于随机算法里面用的是随机数，这里用的是根据参数计算出来的哈希值

**哈希算法的选取会严重影响负载均衡的效果**，假如说你计算哈希值的算法不太好，就容易导致某几个节点上负载特别高，而其他节点的负载就比较低。所以要尽可能保证哈希值计算出来的结果是均匀的

![](image/Pasted%20image%2020250218222705.png)

相比之下**一致性哈希负载均衡**才算是真正的面试热点

一致性哈希负载均衡引入了一个哈希环的概念，服务端节点会落在环的某些位置上。客户端根据请求参数，计算一个哈希值。这个哈希值会落在哈希环的某个位置。从这个位置出发，顺时针查找，遇到的第一个服务端节点就是目标节点

注意，在一致性哈希负载均衡算法里面，并不要求服务端节点是均匀分散在哈希环上的。实际上，我们是希望所有的节点负载是均衡的，但是不同节点之间的间隔可以是不均匀的

这里我可以用一个比喻来简单描述这个算法。一致性哈希负载均衡算法就像是钟表，它的过程就有点儿像你的朋友约你吃火锅，说下一个整点到重庆火锅店集合。那么你看一下现在的时间，是下午三点四十五分，那么自然下一个整点就是下午四点了

在面试的时候，如果你实在记不住一致性哈希负载均衡算法，那么可以用这个比喻来向面试官解释一下

![](image/Pasted%20image%2020250218222850.png)

## 最少连接数

最少连接数基于一个基本假设

- 如果一个服务端节点上的连接数越多，那么这个节点的负载就越高

因此在做负载均衡的时候就是看一下客户端和各个节点的连接数量，从中挑选出连接数数量最少的节点

最少连接数算法的缺陷在于，连接数并不能代表节点的实际负载，尤其是在连接多路复用的情况下

比如这张示意图里，理论上来说新来的请求就会落到服务端节点 1 上，而后连接数变成 11。实际上在连接复用的情况下，客户端可能连续发 10 个请求到服务端节点 1 上，才会创建一个新连接

那么很显然，在这种情况下，服务端节点 1 的负载会比其他两个节点高一截

![](image/Pasted%20image%2020250218223032.png)

## 最少活跃数

最少活跃数算法则是用当前活跃请求数来代表服务端节点的负载

- 所谓的活跃请求，就是已经接收但是还没有返回的请求

客户端会维持一个自己发过去但是还没返回的请求数量，然后每次挑选活跃请求最少的那个服务端节点

类似地，活跃请求数量也不能真正代表服务端节点的负载。比如说图中，服务端节点 1 虽然只有 10 个请求，但是万一这 10 个请求都是大请求，例如大商家、大买家或者千万粉丝 UP 主的请求，那么服务端节点 1 的负载也会显著高于其他两个节点

![](image/Pasted%20image%2020250218223219.png)

## 最快响应时间

相比前两个算法，最快响应时间算法则要好很多，

- 响应时间来代表服务端节点的负载

 响应时间和前面的两个指标比起来，是一种综合性的指标，所以用响应时间来代表服务端节点负载要更加准确

最快响应时间算法就是客户端维持每个节点的响应时间，而后每次挑选响应时间最短的。

这里的响应时间，可以是平均响应时间，也可以是 99 线之类的，选择什么其实效果并不会相差很多

但是在实现上，要注意响应时间的时效性。一般来说统计响应时间时应该只用近期请求的响应时间，并且越近的响应时间，权重应该越高。换句话说，就是采集的响应时间效用应该随着时间衰减

![](image/Pasted%20image%2020250218223400.png)

## 总结

那么你在实际工作中也可以利用这个思路来设计自己的负载均衡算法。比如说在 CPU 密集型的应用里面，你可以设计一个负载均衡算法，每次筛选 CPU 负载最低的节点。难点则是你需要考虑**怎么采集到所有服务端节点的 CPU 负载数据**

最少连接数、最少活跃请求数和最快响应时间

- 第一个问题是选择了单一的指标来代表一个节点的负载
- 还有一个问题，就是它们都是客户端来采集数据的。那么不同的客户端就可能采集到不同的数据

如图所示，因为客户端 1 本身并不知道客户端 2 上还有 30 个连接，因此它选择了服务端节点 1。而实际上它应该选择服务端节点 2

那怎么解决这两个问题呢

答案是让服务端上报指标，而不是客户端采集。总体上有两种思路

1. 是服务端在返回响应的时候顺便把服务端上的一些信息一并返回。这种思路需要微服务框架支持从服务端往客户端回传链路元数据
2. 第二种思路是从观测平台上查询。例如通过查询 Prometheus 来获得各种指标数据

不过目前业界很少用这种复杂的负载均衡算法，也因此几乎所有的微服务框架都没有服务端上报指标到客户端的机制。

![](image/Pasted%20image%2020250218223543.png)

## 面试准备

### 基本思路

首先我前面提到的这些算法，你都要记下来。尤其要对这几个算法格外上心一些。

- 轮询和加权轮询
	- 对应的平滑加权轮询算是一个小亮点
- 一致性哈希负载均衡
	- 这个可以结合 Redis 之类的使用了一致性哈希算法的中间件一起理解
- 最快响应时间算法
	- 这个算法体现了采集指标随着时间准确性衰减的特性，后面在服务治理的部分你会再次接触到类似的东西

那么我们对这些算法的简单分析你也要记住，尤其是在小结里提到的采集指标的问题。然后你在准备项目经验的时候要搞清楚公司以下几种情况

- 如果公司有 Nginx 之类的网关，或者微服务网关，那么用的是什么负载均衡算法
- 如果公司用客户端负载均衡的话，用的是什么负载均衡算法
- 有没有出过和负载均衡相关的事故，如果有，那么是什么原因导致的，怎么解决的这个事故，它体现了负载均衡算法的什么缺陷

另外，你还可以尝试根据业务设计一个独一无二的负载均衡算法。即便你用的是最简单的轮询之类的算法，也不用担心。因为目前大规模应用的就是这种简单的算法，那些花里胡哨的算法在面试和汇报晋升的时候很有用，但是实际上落地的并不多

如果你现在有足够的时间，那么前面这些算法你都可以试着实现一下。我尤其建议你在 gRPC 里接入一下自己写的算法，做个小实验。一方面是加深理解，另一方面是防止面试官要求你现场写算法实现

小结中讨论的内容可以作为一个亮点，但是稍微有点理论化，所以你还需要掌握一些实践方面的答题亮点

- 怎么根据调用结果来调整权重，从而影响负载均衡的效果
- 怎么利用一致性哈希负载均衡算法, 来提高本地缓存命中率，缓解数据不一致性问题？

这两个问题你可以从后面找到答案

### 亮点方案

正常来说，面试官会先问你“是否了解负载均衡”“知道哪些负载均衡算法”之类的问题，那么你就可以列举前置知识里面提到的算法，然后要结合自己公司的实际情况，说明自己用的是什么负载均衡算法

如果你准备了一个负载均衡引发的线上事故案例，那么一定要记得展开聊一聊。这里我用轮询作为例子，你可以参考这个例子来准备

首先在回答里面你要先描述各种基本算法以及简要分析，然后再加上一句总结引导

- 一般来说，加权类的算法都要考虑权重的设置和调整

紧接着你开始说你们公司的负载均衡算法，关键词是**大请求**，你可以这么说

- 我们公司用的是轮询来作为负载均衡。不过因为轮询没有实际查询服务端节点的负载，所以难免会出现偶发性的负载不均衡的问题
- 比如说我们之前发现线上的响应时间总体来说是非常均匀的，但是每隔一段时间就会出现响应时间特别慢的情况。而且时间间隔是不固定的，慢的程度也不一样，所以就很奇怪。后来我们经过排查之后，发现是因为当一个大请求落到一个节点的时候，它会占据大量的内存和 CPU。如果这时候再有请求打到同一个节点上，这部分请求的响应时间就会非常慢

在这个回答里我用的这个例子说明了所有负载均衡算法都有的缺点，即**没有考虑请求本身**

一个头部商家拉当日成交订单数据，和一个尾部商家拉当日成交订单数据，能是一回事吗？显然不是

在这个例子里面，我并没有说怎么解决问题，其实这也是在引导面试官进一步问。如果他问如何解决，那么你可以从**业务拆分**或者**隔离**的角度回答

- （业务拆分）这个大请求其实是一个大的批量请求。后来我们限制一批最多只能取 100 个，有什么问题找客服提工单
- （隔离角度）我们稍微魔改了一下负载均衡算法，不再是单纯的轮询了。我们每天计算一批大客户，这部分大客户的请求会在负载均衡里面被打到专门的几个节点上。虽然大客户的请求依旧很慢，但是至少别的客户不会再受到他们的影响了

隔离角度的回答相比之下会更加高级一点，因为你可以借此机会将这个回答引到服务治理中的隔离措施这个话题上。同时，这个角度还体现了一个魔改负载均衡的创新点。但如果你不太熟悉服务治理类的话题，那么用业务拆分的角度来回答会更加合适

这时候你可以补上一句总结，升华一下回答

- 负载均衡算法有些时候用得好，是能够解决一些技术问题的，比如说缓存

这里你应该能够看出来，不论是刚刚说的“加权类的算法都要考虑权重设置和调整”还是这个“能够解决一些技术问题的”，都是在钓鱼。这两个点也就是你能彻底拉开和其他候选者差距的亮点

### 调用结果对负载均衡的影响

前面我和你提到过在负载均衡里面有对应的加权版本，比如说轮询有对应的加权轮询版本，随机也有对应的加权随机版本

而实际上在工作中我们可以考虑根据调用结果来动态调整这个权重。所以如果面试官问你怎么设置权重或者怎么调整权重，抓住关键词**成加败减**就可以了

- 权重代表节点的处理能力，当然在一些场景下它也代表节点的可用性或者重要性。所以权重根据节点的实际情况来设置值就可以。权重的要点在于体现不同节点的差异性，它的绝对值并不重要
	- 解释一下为什么说绝对值不重要
	- 比如说一个方案是 A 的权重是 100，B 的权重是 200，与另一个方案 A 的权重是 1000，而 B 的权重是 2000，负载均衡的效果是一样的。但是在调整权重的时候要按比例来调。比如说前一个方案调整权重可能每次调 10，而后一个方案就要每次调 100。
- 一般来说为了进一步提高可用性，加权类的负载均衡算法都会考虑根据调用结果来动态调整权重。如果调用成功了，那么就增加权重；如果调用失败了，那么就减少权重
- 这里调用成功与否是一种非业务相关的概念，也就是说即便拿到了一个失败的响应，但是本身也算是调用成功了。调用失败了大多数时候是指网络错误、超时等。而在实际落地的时候，也可以考虑如果是网络引起的失败，那么权重下调就多一点，因为这一类的错误意味着问题更加严重。如果是超时这种，那么权重就下调少一点，因为这种错误是比较容易恢复过来的

![](image/Pasted%20image%2020250219010908.png)

回答到这里，还有一个很多开发者都意识不到以至于经常有人踩坑的点

- **权重的调整要设置好上限和下限**

那么你可以揭开这个业界经常忽略的问题，关键词是**上下限**

- 调整权重的算法都要考虑安全问题，即权重的调整应该有上限和下限。比如说一般下限不能为 0，因为一个节点的权重为 0 的话，它可能永远也不会被选中，又或者和 0 的数学运算会出现问题导致负载均衡失败。上限一般不超过初始权重的几倍，比如说两倍或者三倍，防止该节点一直被连续选中
- 当然，如果在实现的时候使用了 uint 或者 Int8 之类的数字，还要进一步考虑溢出的问题。之前挺多公司因为没有控制上下限而引起了线上故障

这里你如果对服务注册与发现烂熟于心，那么就可以尝试将话题引导到服务注册与发现中，关键词是**可用性**

- 这种根据调用结果来调整权重的方式，有点类似于在服务中将暂时调用不通的节点挪出可用节点列表，本质上都是为了进一步提高系统的可用性

### 哈希一致性结合本地缓存

这算是一个微创新的方案。正常情况下，如果你使用本地缓存，那么同一个 key 对应的请求，可能会被打到不同的节点上。这就会造成两个问题，一个是严重的缓存未命中，一个是不同节点都要缓存同样的数据，导致内存浪费和极其严重的数据一致性问题

![](image/Pasted%20image%2020250219011236.png)

所以在这种情况下，一个很自然的想法就是能不能把类似的请求都让同一个节点来处理。比如说对某个用户数据的请求都打到同一个节点上

显然适合的负载均衡算法就两个

- 哈希
- 一致性哈希

如果我们考虑节点可能上线、下线的情况，那么一致性哈希负载均衡就是最优选择。所以你可以先简单介绍一下方案

- 在性能非常苛刻的时候，我们会考虑使用本地缓存。但是使用本地缓存的数据一致性问题会非常严重，而我们可以尝试将一致性哈希负载均衡算法和本地缓存结合在一起，以提高缓存命中率，并且降低本地缓存的总体内存消耗。比如说针对用户的本地缓存，我们可以使用用户 ID 来计算哈希值，那么可以确保同一个用户的本地缓存必然在同一个节点上。不过即便是采用了一致性哈希负载均衡算法，依旧不能彻底解决数据一致性的问题，只能缓解一下

最后一句就是你留下的鱼饵。如果面试官追问为什么不能彻底解决，那么你就可以这样回答，关键词是**应用发布**

当整个集群的节点数量发生变化的时候，就难免会导致同样的数据缓存在多个节点上

- 例如在用户这个例子中，假如最开始有一个请求需要 user_id 为 1 昵称为小明的信息，这个请求最开始会命中老节点。但是此时还没有返回数据。紧接着扩容。此时又来了一个请求，那么它会被导去新节点。这一个请求会将 user_id 为 1 的信息改为小刚。如果这时候第一个请求从老节点的缓存上读出了数据，那么它拿到的就还是老的数据。而应用发布是引起节点数量变化最常见的原因。毕竟应用发布可以看作先下线一个节点，再上线一个节点
- 不过同时也可以看出来，在本地缓存结合了一致性哈希负载均衡算法之后数据一致性的问题已经被大大缓解了

![](image/Pasted%20image%2020250219011859.png)

在这个方案中，你已经主动聊起了缓存和数据一致性的问题，那么面试官很可能就把话题转到缓存和一致性相关的问题。不过你也不用慌，在后面的内容里面我会告诉你如何应对

### 总结

我们主要解决的是负载均衡的问题。我给出了负载均衡的基本算法、面试的思路和亮点方案

其中我提到几个关键词，分别是

- **大请求**
- **成加败减**
- **上下限**
- **可用性**
- **应用发布**

你可以从这几个关键词出发，加上自身真实的案例，梳理自己的面试思路，把这些知识内化为自己的，相信在遇到这些问题的时候，你一定可以让面试官刮目相看

![](image/Pasted%20image%2020250219012048.png)

## 思考题

- 如果单纯从算法效果看，随机和轮询其实差不多。而现在据我观察，使用轮询要比使用随机多得多，你觉得这是为什么
	- 轮询算法和随机算法，从统计学角度来看，最终效果是一样的。但是轮询算法天然的就会比随机算法更平滑，可以避免连读多次请求打到一个节点

- 在基本算法总结里面我用最少连接数算法举了一个反面例子，但是同样的算法用在网关负载均衡上，就没有类似的问题，为什么
	- 客户端统计的连接数只是客户端自己与服务端之间的连接数，并不能代表服务端上所有的连接数，所以不具备参考性。而网关是服务端所有连接的入口，网关上统计的连接数实际上就是服务端的所有连接数，所以这个指标是有参考性的

# 熔断

在微服务架构里面

- 熔断
- 限流 
- 降级

一般是连在一起讨论的，熔断作为微服务架构可用性保障的重要手段之一，是我们必须要掌握的，而且要能够说清楚自己在实践中是怎么利用熔断来提高系统的可用性的

## 介绍

熔断在微服务架构里面是指当微服务本身出现问题的时候，它会拒绝新的请求，直到微服务恢
复

看图，你会不会觉得有点困惑？服务端明明返回了错误的响应，怎么还说熔断提高了系统的可
用性

答案就是**熔断可以给服务端恢复的机会**。试想这么一个场景，CPU 使用率已经 100% 了，服
务端因此触发了熔断。那么拒绝了新来的请求之后，服务端的 CPU 使用率就会在一段时间内降到 100% 以内

![](image/Pasted%20image%2020250219013516.png)

你会不会觉得有点困惑？服务端明明返回了错误的响应，怎么还说熔断提高了系统的可用性呢

答案就是熔断可以给**服务端恢复的机会**，试想这么一个场景，CPU 使用率已经 100% 了，服务端因此触发了熔断。那么拒绝了新来的请求之后，服务端的 CPU 使用率就会在一段时间内降到 100% 以内

回到熔断的基本定义上来，我们可以提炼出两个点进一步讨论

- 怎么判断微服务出现了问题
- 怎么知道微服务恢复了

接下来我们要讨论的亮点也是围绕这两个方面来进行的

## 判定服务的健康状态

第一个问题，判断微服务是否出现了问题，它有点儿像我们在负载均衡里面讨论的动态算法。本质上也是要求你根据自己的业务来选择一些指标，代表这个服务器的健康程度。比如说一般可以考虑使用响应时间、错误率

不管选择什么指标，都要考虑两个因素

1. **是阈值如何选择**
2. **是超过阈值之后，要不要持续一段时间才触发熔断**

比如我们把响应时间作为指标，那么响应时间超过多少应该触发熔断呢？这是根据业务来决定的。比如说如果业务对响应时间的要求是在 1s 以内，那么你的阈值就可以设定在 1s，或者稍高一点，留点容错的余地也可以

那么如果你的产品经理没跟你说这个业务对响应时间的要求，你就可以根据它的整体响应时间设定一个阈值，原则上阈值应该明显超过正常响应时间。比如你经过一段时间的观测之后，发现这个服务的 99 线是 1s，那么你可以考虑将熔断阈值设定为 1.2s

![](image/Pasted%20image%2020250219023019.png)

那么是不是响应时间一旦超过了阈值就立刻熔断呢？一般也不是，而是
**要求响应时间超过一段时间之后才触发熔断**。这主要是出于两个考虑，

1. 是响应时间可能是偶发性地突然增长
2. 则是防止抖动
 
防止抖动这个问题后面进一步讨论

那么这个“一段时间”究竟有多长，很大程度上就依赖个人经验了。如果时间过短，可能会频繁触发熔断，然后又恢复，再熔断，再恢复……反过来，如果时间过长，那就可能会导致该触发熔断的时候迟迟没有触发

你可以根据经验来设定一个值，比如说三十秒或者一分钟

当然最简单的做法就是超过阈值就直接触发熔断，但是采取这种策略就要更加小心抖动问题

![](image/Pasted%20image%2020250219023725.png)

## 服务恢复正常

第二个问题，一个服务熔断之后要考虑恢复。比如说如果我们判断一个服务响应时间过长，进入了熔断状态。那么十分钟过后，已接收的请求已经被处理完了，即服务恢复正常了，那么它就要退出熔断状态，继续接收新请求

因此在触发熔断之后，就要考虑检测服务是否已经恢复正常

![](image/Pasted%20image%2020250219023924.png)

很可惜，这方面微服务框架都做得比较差。大多数情况下就是触发熔断之后保持一段时间，比如说一分钟，一分钟之后就认为服务已经恢复正常，继续处理新请求

不过这里就涉及到我前面多次提到的抖动问题了。所谓**抖动就是服务频繁地在正常 - 熔断两个状态之间切换**

引起抖动的原因是多样的，比如说前面提到的一旦超过阈值就进入熔断状态，或者我们这里说的恢复策略不当也会引起抖动。再比如刚刚我们提到的“一分钟后就认为服务已经恢复正常，继续处理新请求”就容易引发抖动问题

你试想一下，如果本身熔断是高并发引起的。那么在一分钟后，并发依旧很高，这时候你一旦直接恢复正常，然后高并发的流量打过来，服务是不是又会触发熔断

![](image/Pasted%20image%2020250219024102.png)

而要解决这个抖动问题，就需要在恢复之后控制住流量。比如说按照 10%、20%、30%……逐步递增，而不是立刻恢复 100% 的流量

![](image/Pasted%20image%2020250219024112.png)

显然你能够看出来这种做法还是不够好。因为在这种逐步放开流量的措施下，依旧有请求因为熔断不会被处理。那么一个自然的想法就是，**能不能让客户端来控制这个流量**？简单来说就是服务端触发熔断之后，客户端就直接不再请求这个节点了，而是换一个节点。等到恢复了之后，客户端再逐步对这个节点放开流量

当然可以，这也是我给出的亮点方案

## 面试准备

这些就是关于熔断你要了解的基础知识，不过如果你想要彻底掌握，还需要把这些知识点和实际工作联系在一起。所以我建议你在面试之前，要弄清楚你所在的公司有没有用熔断来治理微服务。如果有，那么你需要进一步弄清楚下面这些情况

1. 你们公司是怎么判断微服务出现故障的？比如说错误率、响应时间等等
2. 你们公司是怎么判断微服务已经从故障中恢复过来的
3. 在判断微服务已经恢复过来之后，有没有采取什么措施来防止抖动的问题

关于熔断最佳的面试策略是把它作为你构建一个高可用微服务架构的一环。例如你在介绍某一个微服务项目的时候可以这样说

- 这是一个高可用的微服务系统，为了保证它的可用性，我采取了限流、降级、熔断等措施

此外，如果面试官问到服务治理以及提高系统可用性的方法之类的问题，你也可以用熔断来回答。又或者面试官问到了限流或者降级，那么你就可以尝试把话题引到熔断上面。此外，如果面试官问到某个服务崩溃了怎么办？这个问题相当于是在问怎么提高可用性防止服务崩溃，以及万一服务真崩溃了你也要有措施防止拖累别的服务，那么熔断就是一个可用的手段

### 基本思路

当面试官问“你有没有用过熔断”或者“怎么保障微服务可用性”的时候，你就可以介绍你使用的熔断。但是要根据我在前置知识里面的提示，你在面试的时候要说清楚什么时候判定服务需要触发熔断，为什么选用这个指标

假如说你准备用**响应时间**来作为指标，那么你可以这么回答，关键词是**持续超过阈值**

- 为了保障微服务的可用性，我在我的核心服务里面接入了熔断。针对不同的服务，我设计了不同的微服务熔断策略
- 比如说最简单的熔断策略就是根据响应时间来进行。当响应时间超过阈值一段时间之后就会触发熔断。我一般会根据业务情况来选择这个阈值，例如，如果产品经理要求响应时间是 1s，那么我会把阈值设定在 1.2s。如果响应时间超过 1.2s，并且持续三十秒，就会触发熔断。在触发熔断的情况下，新请求会被拒绝，而已有的请求还是会被继续处理，直到服务恢复正常

这里面试官就可能有很多种问法，但是我在前置知识里面都讨论到了。虽然他的问题可能千奇百怪，不过万变不离这几问

1. 这阈值还可以怎么确定
	- 那么你就回答还可以根据观测到的响应时间数据来确定
2. 这个持续三十秒是如何计算出来的
	- 这个问题其实可以坦白回答是基于个人经验，然后你解释一下过长或者过短的弊端就可以了
3. 为什么多了 0.2s
	- 那么你可以解释是留了余地，防止偶发性的响应时间变长的情况
4. 怎么判断服务已经恢复正常了
	- 那么你可以回答等待一段固定的时间，然后尝试逐渐放开流量

如果你在实践中根据自己的业务特征选用了一些比较罕见的指标，或者你设计的触发熔断的条件比较有特色，那么也可以用自己的实际方案

这里我给你另外一个微创新的方案，关键词是**缓存崩溃**

- 我还设计过一个很有趣的熔断方案。我的一个接口并发很高，对缓存的依赖度非常严重。所以我的熔断策略是要是缓存不可用，比如说 Redis 崩溃了，那么我就会触发熔断。这里如果我不熔断的话，请求会因为 Redis 崩溃而全部落到 MySQL 上，基本上会压垮 MySQL
- 在触发熔断之后，我会额外开启一个线程（如果是 Go 就换成 Goroutine）持续不断地 ping Redis。如果 Redis 恢复了，那么我就会退出熔断状态，新来的请求就不会被拒绝了

这里我用 Redis 来作为例子，你可以将 Redis 替换为 MemCache 之类的，甚至你还可以将缓存替换成你业务上任何一个关键的第三方依赖

![](image/Pasted%20image%2020250219025206.png)

这个方案里面我还留了一些可以引导的点

- 缓存问题：在这里我提到了 Redis 失效，这种情况类似于缓存雪崩，那么你很自然地就可以把话题引导到如何处理缓存击穿、穿透、雪崩这些经典问题上
- 高可用 MySQL：我在这里使用的是熔断来保护 MySQL，类似地，你也可以考虑用限流来保护 MySQL

最后我提到了退出熔断状态，如果面试官了解抖动问题，那么他就肯定会追问“你是一次性放开全部流量吗？”，那么你就可以阐述抖动的问题，然后总结一下

- 我这种逐步放开流量的方案其实还是有缺陷的，还有一些更加高级的做法，但是需要负载均衡来配合

这个总结就是你留下的鱼饵，为了引出下面我给你展示的亮点方案

### 亮点方案

前面的基本思路如果你能答好，差不多也能通过跟熔断有关的面试了，而且有不小的概率能够给面试官留下你技术很不错的印象。但是你还可以进一步展示你在服务治理和服务可用性保证上的独到见解。这就需要用到下面我要给你讲的综合了负载均衡算法和熔断措施的方案了

这个方案很简单，在落地的时候也不是很难

我在讲抖动与恢复的时候提到，恢复的时候可以逐步放开流量。那么你是否注意到，这个放开流量是在服务端处理的，也就是说服务端还是收到了 100% 的流量，只不过只有部分流量会被放过去并且被正常处理

那么一个自然的想法就是**为什么不直接让客户端来控制这个流量呢**

![](image/Pasted%20image%2020250219025422.png)

进一步结合我在负载均衡里面谈到的根据调用结果来调整负载均衡策略的讨论，是不是可以让客户端也采用这种负载均衡策略？答案是可以的

1. 服务端在触发熔断的时候，会返回一个代表熔断的错误
2. 客户端在收到这个错误之后，就会把这个服务端节点暂时挪出可用节点列表。后续所有的新请求都不会再打到这个触发了熔断的服务端节点上了
3. 客户端在等待一段时间后，逐步放开流量
4. 如果服务端正常处理了新来的请求，那么客户端就加大流量
5. 如果服务端再次返回了熔断响应，那么客户端就会再一次将这个节点挪出可用列表
6. 如此循环，直到服务端完全恢复正常，客户端也正常发送请求到该服务端节点

![](image/Pasted%20image%2020250219025611.png)

![](image/Pasted%20image%2020250219025615.png)

![](image/Pasted%20image%2020250219025619.png)

那么这里你就可以这样回答，关键词是**负载均衡**

- 整体思路是利用负载均衡来控制流量。如果一个服务端节点触发了熔断，那么客户端在做负载均衡的时候就可以将这个节点挪出可用列表，后续请求会发给别的节点。在经过一段时间之后，客户端可以尝试发请求给该节点。如果该节点正确处理了，那客户端就可以加大流量。否则客户端就要再一次等待一段时间

到这里你还可以自己杠自己一下，就是**万一所有可用节点都触发熔断了**，应该怎么办？你就可以这样来说

- 这个方案是需要兜底的，比如说如果因为某些原因数据库出问题，导致某个服务所有的节点都触发了熔断，那么客户端就完全没有可用节点了。不过这个问题本身熔断解决不了，负载均衡也解决不了，只能通过监控告警之后人手工介入处理了

### 总结

这节课我们主要解决的是熔断问题。我们讨论了熔断的基本概念，怎么判定服务是否熔断，以及熔断后如何恢复的问题。其中的难点是抖动的问题，为了防止抖动，我们需要合理判定节点的健康状况，在恢复期间尽可能等待一段时间，然后逐步放开流量

最后给出了一个**综合运用负载均衡和熔断的方案，重点在于客户端控制流量，并根据服务端节点的状况来操作可用节点列表**

你在学习的时候注意把亮点方案和前面学习的负载均衡内容结合在一起，同时我也非常建议你在实际工作中尝试应用一下熔断，让它来保护你的系统，提高系统可用性

![](image/Pasted%20image%2020250219025850.png)

除了熔断相关知识，这节课我还希望你学会综合运用各种技术手段来设计精巧的方案。在这里我给出了一个负载均衡 + 熔断的方案，后续你也可以看到更多这个技巧的应用

最后我再强调一下，熔断面试的最好方案是把它作为你**构建高可用微服务**的一环，也就是说，你可以认为前面讨论的负载均衡，还有接下来要讨论的限流、降级、隔离等措施，都是你整个高可用方案的一环

## 思考题

- 负载均衡和熔断里面都提到一个关键点，即如何判定一个服务是否处于健康状态，你有什么思考
	- 判断一个服务是否健康，从调用方的调用来说，可以根据调用的错误和超时率，比如可以配置最小的请求量比如30个，错误请求比例比如30%，超时请求比例如何10%，时间滑动窗口的长度比如60秒。另外在熔断恢复，可以配置恢复等待时长比如60秒，探测初始通过比例比如10%，探测每满n个成功恢复比例比如10%。 在实现中，可以通过代理机制结合时间滑动窗口，对请求的成功和失败进行数据的统计
	- 不是说所有业务都可以熔断。监控与告警是肯定得有的。不过我个人感觉缺乏熔断的最主要问题是故障扩散。就是一个系统崩了之后，把其它系统也一并搞崩了，这个是要比较小心
	- 熔断、限流和降级，都可以考虑在客户端做，也可以考虑在服务端做，各有缺点。客户端做的缺点是，不够准确。比如说你这里 A 熔断了但是没用，因为可能还有 C 继续调用 B。如果此时就是因为 B 有问题，那么很快 C 也会熔断。服务端做的缺点就是，服务端始终会收到请求。在你 GC 的例子里面，就只能靠客户端超时控制了，超时控制是不能仅仅在服务端做的
	- 你后端的节点处理能力是有冗余的，那么一两个节点熔断，这些冗余的处理能力刚好够用。但是如果你要是大部分节点都已经快要撑不住流量了，那么你这时候一两台机器熔断，就会导致其它节点也撑不住。所以这种流量的场景，用限流会更好

# 降级

我们讨论熔断的时候，我就提到过熔断、降级、限流是三个经常合并在一起讨论的可用
性保障措施。所以如果你想要掌握高可用微服务架构，那么降级也是其中必不可少的一环

可惜的是，大部分人在聊起降级的时候只是简单讲一下概念，选择的降级案例也不够精巧，所以很难给面试官留下深刻的印象。那么这节课我就带你来深入讨论降级的各个方面，同时我也会给出具体的亮点的方案。我们还是从降级的基本概念讲起

## 介绍

如果用一句俏皮话来形容降级，那就是“**凑合过呗，还能离咋的**。”就比如在双十一之类的大
促高峰，平台是会关闭一些服务的，比如退款服务

这就是降级的典型应用，不过它是一种手动的跨服务降级。你可能会觉得困惑，这为什么也算是降级呢？这是因为对于整个系统来说，它提供了一部分服务，但是没有提供另外一部分服务，所以它在整个系统层面上是降级的

这种降级的好处有两方面。一方面是腾出了服务器资源，可以给订单服务或者支付服务；另外一方面是减少了对公共组件的压力，比如说减少了对数据库的写入压力

不过如果仅仅是针对退款服务而言，那么你也可以认为退款服务是整个熔断了

![](image/Pasted%20image%2020250219150332.png)

## 降级与熔断

事实上，降级和熔断非常像。熔断重点讨论的两个点，降级也有讨论

- 如何判定服务健康，在降级中则是判定一个服务要不要降级
- 降级之后怎么恢复，也是要考虑抖动的问题

所以在一些场景下，你既可以用熔断，也可以用降级。比如说在响应时间超过阈值之后，你可以考虑选择熔断，完全不提供服务；你也可以考虑降级，提供有损服务

原则上来说，是应该优先考虑使用降级的。然而有些服务是无法降级的，尤其是写服务。例如你从前端接收数据，然后写到数据库，这种场景是无法降级的。另外，如果你希望系统负载尽快降低，那么熔断要优于降级

从具体实践上来说，降级可以玩出的花样要比熔断多很多。毕竟熔断是彻底不提供服务，而降级则是尽量提供服务。所以**怎么降**就有很多千奇百怪的做法了

![](image/Pasted%20image%2020250219150508.png)

## 如何降级

怎么降这个问题的答案又可以分成两大类

- **跨服务降级**
	- 当资源不够的时候可以暂停某些服务，将腾出来的资源给其他更加重要、更加核心的服务使用。我这里提到的大促暂停退款服务就是跨服务降级的例子。这种策略的要点是必须知道一个服务比另外一个服务更有业务价值，或者更加重要。
- **本服务提供有损服务**
	- 例如各大 App 的首页都会有降级的策略。在没有触发降级的时候，App 首页是针对你个人用户画像的个性化推荐。而在触发了降级之后，则可能是使用榜单数据，或者使用一个运营提前配置好的静态页面。这种策略的要点是你得知道你的服务调用者能够接受什么程度的有损

![](image/Pasted%20image%2020250219150706.png)

跨服务降级的措施是很粗暴的，常见的做法有三个

- 整个服务停掉，例如前面提到的停掉退款服务
- 停掉服务的部分节点，例如十个节点，停掉其中五个节点，这五个节点被挪作他用。
- 停止访问某些资源。例如日志中心压力很大的时候，发信号给某些不重要的服务，让它们停止上传日志，只在本地保存日志

![](image/Pasted%20image%2020250219150953.png)

而针对服务本身，也有一些常见的降级思路

- 返回默认值，这算是最简单的一种状况
- 禁用可观测性组件，正常来说在业务里面都充斥了各种各样的埋点。这些埋点本身其实是会带来消耗的，所以在性能达到瓶颈的时候，就可以考虑停用，或者降低采样率。
- 同步转异步，即正常情况下，服务收到请求之后会立刻处理。但是在降级的情况下，服务在收到请求之后只会返回一个代表“已接收”的响应。后续服务会异步地开启线程来处理，或者依赖于定时任务来处理。
- 简化流程，如果你处理一个请求需要很多步骤，后续如果有一些步骤不关键的话，可以考虑不执行，或者异步执行。例如在内容生产平台，一般新内容要被推送到推荐系统里面。那么在降级的情况下你可以不推，而后可以考虑异步推送过去，也可以考虑等系统恢复之后再推送过去

![](image/Pasted%20image%2020250219151001.png)

## 面试准备

在面试前，你需要了解清楚你所在公司使用降级的情况

- 如果你所在公司有 App、网站之类的产品，那么去了解一下在首页、核心页面有没有采取降级措施。如果采用了降级，那么降级前后的逻辑是什么样的
- 提前了解你所在公司有没有使用降级来保护系统。如果有，那么你需要了解清楚什么情况下会触发降级，降级后的逻辑是怎样的，以及怎样从降级中恢复过来

这些降级的东西可能你没做过，不过你只需要了解清楚每一种降级的前因后果即可

如果你维护的服务没有使用任何降级措施，那么你可以考虑为这些服务接入降级措施。这样做不仅可以给你的 KPI 或者 OKR 添上一笔，还能让你在实践过程中加深对降级的理解，掌握更多的细节

你的最佳面试策略是把降级作为构建高可用微服务架构的一个措施，例如在项目介绍中说

- A 系统是我们公司的核心系统，而我的主要职责是保障该系统的高可用。为了达到这一个目标，我综合运用了熔断、降级、隔离等措施

等面试官询问某个具体措施的时候再详细解答

知己知彼，方能百战不殆。当面试官问哪些问题时我们可以用降级来回答

- 你是否了解服务治理
- 如何提高系统的可用性
- 如果系统负载很高该怎么办
- 依赖的下游服务或者下游中间件崩溃了怎么办

这些问题是不是很熟悉，其实我们已经在熔断里面聊过了。就像我上节课说的，这些知识之间是相通的，任何优秀的方案都是这些内容的完美整合。所以这些问题你同样可以用降级来回答

同时为了展示亮点，需要理解后面我给出的两个方案

- [读写服务降级写服务](#读写服务降级写服务)
- [快慢路径降级慢路径](#快慢路径降级慢路径)

你可以参考这两个方案的思路，基于自己的实际业务情况设计自己独有的降级面试案例

### 基本思路

如果面试官问到了降级，或者说你将话题引导到了降级，那么你可以先介绍降级的基本概念，同时可以举前面我们提到的大促和 App 首页的例子。如果你之前没有和面试官聊过熔断，那么你可以在这里补充熔断里面讨论判断服务健康的要点，然后结合自己公司内部使用降级的例子，或者即便不是自己亲手落地但是自己也了解详情的案例

- 我在公司也用了降级来保护维护的服务。举例来说，正常情况下我的服务都会全量采集各种监控指标。那么在系统触及性能瓶颈的时候，我就会调整采集的比率。甚至在关键的时候，我会直接停用掉所有的指标采集，将资源集中在提供服务上

我在这里给你的示例比较简单，你可以考虑换成我在前面提到的其他降级思路。当然，如果你在公司内部本身就使用了降级的话，那么使用自己的案例会更好。讲完一个案例之后，你可以进一步总结常规的降级思路，也就是我在介绍里面列举出来的。 套路是一样的，这里就不再赘述

我前面列举出来的这些措施你不一定都用过，那么万一面试官问到其中一个，你不了解细节的话，你可以大方承认这就是听说过的措施，并没有实际落地。毕竟，技术行业乱七八糟、千奇百怪的解决思路数不胜数，不一定非得都亲手实践过

紧接着，还有一个关键问题**抖动**，千万别忘记参考熔断中的话术提一下。而后你可以将熔断与降级结合，总结升华一下

- 总的来说，在任何的故障处理里面，都要考虑恢复策略会不会引起抖动问题

总结是必不可少的，任何总结都代表你对问题更加抽象、更加深层次的认知

### 亮点方案

到这一步，从理论上来说你基本上已经答得很好，唯一美中不足的就是案例过于简单。所以这里我给你准备了两个比较好的案例，你可以参考。这两个案例你都可以根据你所在公司的实际情况进行调整，用真实的服务来替代我这里使用的服务

#### 读写服务降级写服务

这个案例的基本思路是如果你的某个服务是同时提供了读服务和写服务，并且读服务明显比写服务更加重要，那么这时候你就可以考虑降级写服务

假如说现在我有一个针对商家的服务，商家调用这些 API 来录入一些数据，比如他们门店的基本信息，上传一些门店图片等。同时我还有一个针对 C 端普通用户的服务，这个服务就是把商家录入的数据展示在商家门店的首页上。所以你可以看到在这个场景下，**读服务 QPS 更高，也更加重要**

那么如果这两个服务是一起部署的，在需要降级的时候，就可以考虑将针对商家的写服务停掉，将资源都腾出来给针对 C 端用户的读服务

所以你可以介绍这个方案，关键词是**降级写服务**

- 我在公司维护了一个服务，它的接口可以分成两类
	- 一类是给 B 端商家使用的录入数据的接口
	- 另外一类是给 C 端用户展示这些录入的数据
- 所以从重要性上来说，读服务要比写服务重要得多，而且读服务也是一个高并发的服务于是我接入了一个跨服务的降级策略。
- 当我发现读服务的响应时间超过了阈值的时候，或者响应时间开始显著上升的时候，我就会将针对 B 端商家用户的服务临时停掉，腾出来的资源都给 C 端用户使用。对于 B 端用户来说，他们这个阶段是没有办法修改已经录入的数据的。但是这并不是一个特别大的问题。当 C 端接口的响应时间恢复正常之后，会自动恢复 B 端商家接口，商家又可以修改或者录入数据了

同时你可以考虑从对**数据库性能影响结合缓存**的角度来进一步解释降级写服务的优点

- 虽然整体来说写服务 QPS 占比很低，但是对于数据库来说，一次写请求对性能的压力要远比一次读请求大。所以暂停了写服务之后，数据库的负载能够减轻不少
- 并且暂停了写入，可以提前缓存头部大商家的数据，避免请求直接打到数据库

![](image/Pasted%20image%2020250219153554.png)

除了这种 B 端录入 C 端查询的场景，还有很多类似的场景也适用

- 在内容生产平台，作者生产内容，C 端用户查看生产的内容。那么在资源不足的情况下可以考虑停掉内容生产端的服务，只保留 C 端用户查看内容的功能
- 如果你的用户分成普通用户和 VIP 用户，那么你也可以考虑停掉给普通用户的服务。甚至，如果一个服务既提供给普通用户，也提供给 VIP 用户，你可以考虑将普通用户请求拒绝掉，只服务 VIP 用户

如果你负责的业务也有其他类似的场景，那么你可以将里面的商家服务和 C 端服务换成你自己的服务

在讲完这一个方案之后，你要稍微总结一下，在理论层面上拔高一下

- 这个方案就是典型的跨服务降级。跨服务降级可以在大部分合并部署的服务里面使用，一般的原则就是
	- B、C 端合并部署降级 B 端
	- 付费服务和非付费服务降级非付费服务
	- 当然也可以根据自己的业务价值，将这些部署在同一个节点上的服务分成三六九等。而后在触发降级的时候从不重要的服务开始降级，将资源调配给重要服务

![](image/Pasted%20image%2020250219153843.png)

有时候面试官可能会问怎么确定一个服务的业务价值，又或者你可以自己引出这个话题，关键词就是**赚钱**

- 判断一个服务的业务价值最简单的方法就是问产品经理，产品经理自然是清楚什么东西带来了多少业务价值。又或者根据公司的主要营收来源确定服务的业务价值，越是能赚钱的就越重要
- 唯一的例外是跟合规相关的。比如说内容审核，它不仅不赚钱，还是一块巨大的成本支出。但是不管怎么降级，内容审核是绝对不敢降级的，不然就等着被请去喝茶交代问题吧

这里我们还可以进一步展示亮点，让人感觉你对微服务框架有很深研究。关键词就是**跨节点**

- 不过这种跨服务降级都是只能降级处在同一个节点的不同服务。而如果服务本身就分布在不同节点上的话，是比较难设计这种降级方案的。比如说大促时关闭退款服务这种，就需要人手工介入
- 从理论上来说，网关其实是可以考虑支持这种跨节点的服务降级的。假如说我们有 A、B 两个服务，A 比 B 更加有业务价值。那么在 A 服务所需资源不足的时候，网关可以考虑停掉 B 的一部分节点，而后在这些节点上部署 A 服务。对于 B 服务来说，它只剩下一部分节点，所以也算是被降级了。很可惜，大部分网关的降级设计都没考虑过这种跨服务降级的功能
- 微服务框架做得就更差了。大部分微服务框架提供的降级功能都是针对本服务的，比如说在触发降级的时候返回一个默认值

![](image/Pasted%20image%2020250219154020.png)

最后对网关的评价可能会让面试官将话题引向网关，所以你要在对面试网关内容有把握的情况下再说

#### 快慢路径降级慢路径

我在熔断里面提到了一个例子，即如果 Redis 崩溃了，那么就可以直接触发熔断。这种做法主要是为了保护数据库，防止 Redis 崩溃把所有的请求都直接落到数据库上，把数据库打崩

你也可以考虑使用降级来保护这个缓存 - 数据库结构。正常来说，你使用缓存基本上都是先从缓存里面读数据，如果缓存里面没有数据，就从数据库中读取

那么在触发降级的情况下，你可以考虑只从缓存里面读取。如果缓存里面没有数据，那么就直接返回，而不会再去数据库里读取。这样可以保证在缓存里面有数据的那部分请求可以得到正常处理，也就是提供了有损服务

![](image/Pasted%20image%2020250219154549.png)

这种降级方案背后的逻辑也很简单。如果完全不考虑从数据库里取数据，那么你的性能瓶颈就完全取决于缓存或者说 Redis，那么服务能够撑住的 QPS 会非常高

但是，如果缓存不命中的时候要去数据库取数据，那么服务的性能会衰退得非常快，即极少数缓存未命中的请求会占据大部分的系统资源

![](image/Pasted%20image%2020250219154616.png)

所以你可以这样回答，关键词是**只查缓存**

- 我还用过另外一个降级方案。正常来说在我的业务里面，就是查询缓存，如果缓存有数据，那么就直接返回。如果缓存没有，那么就需要去数据库查询。如果此时系统的并发非常高，那么我就会采取降级策略，将请求标记为降级请求。降级请求只会查询缓存，而不会查询数据库。如果缓存没有，那就直接返回错误。这样能够有效防止因为少部分请求缓存未命中而占据大量系统资源，导致系统吞吐量下降和响应时间显著升高

同样地，你也需要总结拔高一下，关键词是**快慢路径**

- 这种思路其实可以在很多微服务里面应用。如果一个服务可以分成快路径和慢路径两种逻辑，那么在降级之前就可以先走快路径，再走慢路径。而触发了降级之后，就只允许走快路径。在前面的例子里面，从缓存里加载数据就是快路径，从数据库里面加载数据就是慢路径
- 慢路径还可以是发起服务调用或者复杂计算。比如说一个服务快路径是直接查询缓存，而慢路径可能是发起很多微服务调用，拿到所有响应之后一起计算，算出来一个结果并缓存起来。那么在降级的时候，可以有效提高吞吐量。不过这种吞吐量是有损的，毕竟部分请求如果没有在缓存中找到数据，那么就会直接返回失败响应

![](image/Pasted%20image%2020250219154734.png)

很自然地，你的关键服务都应该有类似的降级措施。当任何下游崩溃，或者第三方中间件崩溃，你都可以不再调用这些崩溃的下游服务或中间件，以确保提供有损服务

如果你选择这个作为亮点方案的话，那么自然就可以将话题引导到缓存的使用上来，你就可以使用课程后面缓存相关的内容来阐述了

### 总结

这一节课我们已经讨论清楚了降级的基本概念、常见做法

降级和熔断是很像的，它也要考虑判定服务健康，如何恢复以及怎么降级。你需要记住的是

- 从系统整体上看，你可以考虑**跨服务降级**
	- 例如大促的时候关闭退款服务
- 针对单一服务也可以考虑提供有损服务

最后我给出了两个亮点方案：

- **读写服务降级写服务**
- **快慢路径降级慢路径**

你可以把这两个方案记下来，也可以根据自己的业务特征来设计类似的降级方案

我再强调一点，我提供的这些方案本身都是可以在公司内部落地的。所以即便没有机会也应该创造机会在公司内部实践一下

![](image/Pasted%20image%2020250219155745.png)

## 思考题

那么你觉得写服务内部可以考虑降级吗？比如说我的写服务是写多个数据源，那我可以降级为只写一个数据源吗

- 如果写服务内部还能根据重要程度拆分的话，内部也可以考虑降级。比如对商家的大部分接口都停用了，但是保留修改商品价格和商品下架的接口，如果发生了 BUG 价之类的事故，商家还有机会即时止损。对于写多个数据源的情况，在不影响业务的前提下，可以先写部分数据源，然后通过异步等手段，再来写其它数据源。
- 写多个数据源，就是看业务，业务能接受就可以降级
- 写多个数据源降级为写一个数据源的场景，要细化为2个子场景分别分析
	1. 多个数据源同步写 
	2. 多个数据源异步写
1. 多个数据源同步写这种情况，说明数据很重要，且对数据的一致性要求较高，首先要评估这种情况是否要优先考虑熔断。如果要保证可用性，不熔断，那么优先考虑同步写一个数据源，其他的改为异步，还不行再考虑逐步停掉一些服务。无论哪种方式的降级，都要事先想清楚保证数据一致性的方案再做降级，对万一发生数据不一致留有预案
2. 多个数据源异步写还可以继续拆子场景
	1. 同步写一个数据源，其他数据源异步
	2. 全部数据源都是异步
- 写对于子场景（1），其他数据源本来就是异步的，只要保证同步的数据源写即可，异步的都降级掉没有问题，如果同步写的服务要关停了，那就可以考虑熔断了
- 对于子场景（2），说明数据的重要程度和一致性不高，降级为异步写一个数据源没有问题

熔断和降级，你是怎么看待这两者的关系的？你能举一些可以降级或者只能熔断的服务的例子吗

- 熔断和限流都是提高系统可用性的措施
- 限流是通过主动降低服务质量，来保证系统核心功能能正常运行
- 熔断是通过停止服务，来避免出现连锁故障
- 比如第三方短信平台挂了，本地的短信服务可以直接熔断，拒绝所有发短信的请求；也可以尝试降级，在第三方恢复前都返回一个明确的错误码，告诉用户不能发短信的原因，避免用户不断重试
- 如果是订单的数据库挂了，用户的订单数据没法写入数据库，那么订单服务就只能进行熔断，在订单数据库恢复前，订单服务没法提供任何服务

# 限流

熔断、降级和限流是最常见的三种微服务架构可用性保障措施。和熔断、降级比起来，限流要更加复杂一些。大部分情况下，面试官面试限流就是随便问问算法，最多就是问问 BBR 之类的动态算法。但是有一个问题，很多人都答不好，就是**限流需要确定一个流量阈值，这个阈值该怎么算？**

## 介绍

限流是通过限制住流量大小来保护系统，它尤其能够**解决异常突发流量打崩系统的问题**，例如常见的某个攻击者攻击你维护的系统，那么限流就能极大程度上保护住你的系统

要想全面掌握限流这个知识点，我们需要深入理解限流的算法、对象，以及限流后的做法。下面我们一个一个来看

## 算法

限流算法也可以像负载均衡算法那样，划分成静态算法和动态算法两类

- 静态算法包含令牌桶、漏桶、固定窗口和滑动窗口。这些算法就是要求研发人员提前设置好阈值。在算法运行期间它是不会管服务器的真实负载的
- 动态算法也叫做自适应限流算法，典型的是 BBR 算法。这一类算法利用一系列指标来判定是否应该减少流量或者放大流量。动态算法和 TCP 的拥塞控制是非常接近的，只不过 TCP 控制的是报文流量，而微服务控制的是请求流量

下面我们就从静态算法中的令牌桶看起，掌握限流中常见的算法

### 令牌桶

**系统会以一个恒定的速率产生令牌，这些令牌会放到一个桶里面，每个请求只有拿到了令牌才会被执行**。每当一个请求过来的时候，就需要尝试从桶里面拿一个令牌。如果拿到了令牌，那么请求就会被处理；如果没有拿到，那么这个请求就被限流了

![](image/Pasted%20image%2020250219165729.png)

你需要注意，本身令牌桶是可以积攒一定数量的令牌的。比如说桶的容量是 100，也就是这里面最多积攒 100 个令牌。那么当某一时刻突然来了 100 个请求，它们都能拿到令牌

### 漏桶

漏桶是指当请求以不均匀的速度到达服务器之后，限流器会以固定的速率转交给业务逻辑

某种程度上，你可以将漏桶算法看作是令牌桶算法的一种特殊形态。你将令牌桶中桶的容量设想为 0，就是漏桶了

![](image/Pasted%20image%2020250219170136.png)

所以你可以看到，在漏桶里面，令牌产生之后你就需要取走，没取走的话也不会积攒下来。因此**漏桶是绝对均匀的**，而令牌桶不是绝对均匀的

![](image/Pasted%20image%2020250219170219.png)

### 固定窗口与滑动窗口

**固定窗口是指在一个固定时间段，只允许执行固定数量的请求**。比如说在一秒钟之内只能执行 100 个请求

滑动窗口类似于固定窗口，**也是指在一个固定时间段内，只允许执行固定数量的请求**。区别就在于，滑动窗口是平滑地挪动窗口，而不像固定窗口那样突然地挪动窗口

![](image/Pasted%20image%2020250219170518.png)

假设窗口大小是一分钟。此时时间是 t1，那么窗口的起始位置是 t1-1 分钟。过了 2 秒之后，窗口大小依旧是 1 分钟，但是窗口的起始位置也向后挪动了 2 秒，变成了 t1 - 1 分钟 + 2 秒。这也就是滑动的含义

## 限流对象

此外我们还要进一步考虑限流对象，也就是针对什么来进行限流

从单机或者集群的角度看，可以分为单机限流或者集群限流。集群限流一般需要借助 Redis 之类的中间件来记录流量和阈值。换句话说，就是你需要用 Redis 等工具来实现前面提到的限流算法。当然如果是利用网关来实现集群限流，那么可以摆脱 Redis

![](image/Pasted%20image%2020250219170648.png)

针对业务对象限流，这一类限流对象就非常多样

- VIP 用户不限流而普通用户限流
- 针对 IP 限流。用户登录或者参与秒杀都可以使用这种限流，比方说设置一秒钟最多只能有 50 个请求，即便考虑到公共 IP 的问题，正常的用户手速也是没那么快的
- 针对业务 ID 限流，例如针对用户 ID 进行限流

![](image/Pasted%20image%2020250219170726.png)

## 限流后的做法

即使一个请求被限流了，那么我们也可以设计一些精巧的方案来处理

- 同步阻塞等待一段时间
	- 如果是偶发性地触发了限流，那么稍微阻塞等待一会儿，后面就有极大的概率能得到处理。比如说限流设置为一秒钟 100 个请求，恰好来了 101 个请求。多出来的一个请求只需要等一秒钟，下一秒钟就会被处理。但是要注意控制住超时，也就是说你不能让人无限期地等待下去
- 同步转异步
	- 这里我们又一次看到了这个手段，它是指如果一个请求没被限流，那就直接同步处理；而如果被限流了，那么这个请求就会被存储起来，等到业务低峰期的时候再处理。这个其实跟降级差不多
- 调整负载均衡算法
	- 如果某个请求被限流了，那么就相当于告诉负载均衡器，应该尽可能少给这个节点发送请求。我在熔断里面给你讲过类似的方案。不过在熔断里面是负载均衡器后续不再发请求，而在限流这里还是会发送请求，只是会降低转发请求到该节点的概率。调整节点的权重就能达成这种效果

![](image/Pasted%20image%2020250219170941.png)

![](image/Pasted%20image%2020250219170947.png)

## 面试准备

理论上，你要能够说出各种算法的基本原理。但动态算法，比如 BBR，就不作硬性的要求了。这主要是因为 BBR 的原理和实现都很有难度，大多数微服务框架都没提供 BBR 的限流器实现。不过还是那句老话，你要是有时间和精力，还是可以了解一下 BBR 的基本原理

有些时候面试官可能会让你手写限流算法，那么漏桶、令牌桶、滑动窗口和固定窗口这几个算法你都要能写出来，至少要能把基本思路写清楚。如果你还有时间和精力，那么我建议你为一些开源框架提供限流插件，比如说为 gRPC 提供各种限流算法实现的插件

你可能会说，现在开源的那么多，你写出来的插件还有人用吗？大概率没人用，但是你的目标也不是让人用，而是作为一个证据，来证明你懂限流，你很熟悉 gRPC，你喜欢开源

![](image/Pasted%20image%2020250219171550.png)

除了这些基本的知识，在面试前，你还需要了解清楚你们公司使用限流的情况。正常来说，核心 HTTP 请求和核心服务都应该使用限流来保障系统的可用性。对于每一个限流，你都要了解这些信息

- 限流的阈值是多少，为什么设定成这个阈值
- 被限流的请求会被怎么处理，是直接拒绝还是阻塞直到超时，还是转为异步处理

同样，面试限流的最好策略就是为自己打造一个掌握了高可用微服务架构的人设。而限流就是你在提高系统可用性时的一个具体策略。如果你前面和面试官已经聊到了熔断和降级，那么就可以直接把话题引导到限流上。比如

- 在讨论对外的 API，如 HTTP 接口或者公共 API 时，可以强调使用限流来保护系统
- 在讨论 TCP 拥塞控制时，你可以提起在服务治理上限流也借鉴了 TCP 拥塞控制的一些思想
- 在讨论 Redis 或者类似产品的时候，你可以提你用 Redis 实现过集群限流

如果你维护的服务或者接口还没有使用限流来保护系统，那么你就可以考虑加上限流。而为了确定具体的阈值，你可以尝试对接口进行压力测试，找准限流的阈值。这个也是需要你通过实践来加深印象、把握细节的

### 基本思路

如果面试官问到了限流，那么你就可以先阐述限流的总体目标，然后回答里面的三个点：算法、限流对象和限流后的做法，最后再把话题引到计算阈值上

- 限流是为了保证系统可用性，防止系统因为流量过大而崩溃的一种服务治理手段。从算法上来说，有令牌桶、漏桶、固定窗口和滑动窗口算法。还有动态限流算法，或者说自适应限流算法，比较有名的就是参考了 TCP 拥塞控制算法 BBR 衍生出来的算法，比如说 B 站开源的 Kratos 框架就有一个实现。这些算法之间比较重要的一个区别是能否处理小规模的突发流量
- 从限流对象上来说，可以是集群限流或者单机限流，也可以是针对具体业务来做限流。比如说在登录的时候，我们经常针对 IP 进行限流。又或者在一些增值服务里面，非付费用户也会被限流。
- 触发限流之后，具体的措施也可以非常灵活。被限流的请求可以同步阻塞一段时间，也可以考虑同步转异步。如果负载均衡算法灵活的话，也可以做一些调整，减少发到该节点的概率
- 用好限流的一个重要前提是能够设置准确的阈值，例如每秒钟限制在 100 个请求还是限制在 200 个请求。如果阈值过低，那么系统资源就容易闲置浪费；如果阈值太高，那么系统可能撑不住那么多流量，导致崩溃

同时你还要补充一个简单的例子，关键词是**IP 限流**。你也可以考虑使用你的真实案例

 - 我在我们公司的登录接口里面就引入了限流机制。正常情况下，一个用户在一秒钟内最多点击一次登录，所以针对每一个 IP，我限制它最多只能在一秒内提交 50 次登录请求。这个 50 充分考虑到了公共 IP 的问题，正常用户是不可能触发这个阈值的。这个限流虽然很简单，但是能够有效防范一些攻击。不过限流再怎么防范，还是会出现系统撑不住流量的情况

![](image/Pasted%20image%2020250220020303.png)

注意在上面的回答里，我们没有说任何的细节，只是宽泛地介绍了一下限流，那么面试官接下来大概会问每一个算法、不同的限流对象，以及限流后的不同做法的细节。这部分你按照前置知识里面的内容来回答就可以

同时，如果你开源了一个限流的仓库，你可以一起介绍一下

- 我在 GitHub 上有一个开源仓库，里面放了我为 gRPC 实现的各种限流算法，包括基于 Redis 实现的集群限流版本

如果你是跨语言面试，比如你是 Python 转 Go，你就可以强调一下，这个原本在我司是 Python 写的，后来我用 Go 又写了一遍。如果你有进行一些改进，你可以把你具体改进的内容表述出来

接下来是一些对限流的深入讨论，这部分内容能让你刷出不少的亮点

### 突发流量

前面我们提到了“算法之间比较重要的一个区别是能否处理小规模的突发流量”，就是为这个部分的详细阐述留下了一个引子

假如说正常你的限流是一秒钟 100 个请求，但是如果某一秒钟来了 101 个请求，你依旧会觉得第 101 个请求应该尽可能处理掉。在这种场景下，漏桶是做不到的，因为漏桶是非常均匀的。一秒钟 100 个请求在漏桶里面就是 10 毫秒一个请求，绝对不会多也不会少

而令牌桶就能够处理。比如说令牌桶产生令牌的速率是 100 个每秒，但是桶的容量是 20 个，那么也就是说某一秒钟内，最多可以处理 120 个请求

$$
20（前一秒攒的令牌） + 100（当下这一秒） = 120
$$

![](image/Pasted%20image%2020250220020940.png)

固定窗口和滑动窗口则有另外一个类似的问题，就是**毛刺问题**

假如一个窗口大小是一分钟 1000 个请求，你预计这 1000 个请求会均匀分散在这一分钟内。那么有没有可能第一秒钟就来了 1000 个请求？当然可能。那当下这一秒系统有没有可能崩溃？自然也是可能的

所以固定窗口和滑动窗口的窗口时间不能太长。比如说以秒为单位是合适的，但是以分钟作为单位就是不合适的

![](image/Pasted%20image%2020250220021022.png)

那么在面试官问到，或者你在介绍了漏桶或令牌桶算法之后，就可以补充这一段

- 漏桶算法非常均匀，但是令牌桶相比之下就没那么均匀。令牌桶本身允许积攒一部分令牌，所以如果有偶发的突发流量，那么这一部分请求也能得到正常处理。但是要小心令牌桶的容量，不能设置太大。不然积攒的令牌太多的话就起不到限流效果了。例如容量设置为 1000，那么要是积攒了 1000 个令牌之后真的突然来了 1000 个请求，它们都能拿到令牌，那么系统可能撑不住这突如其来的 1000 个请求

### 请求大小

刚刚我们讨论的限流是针对请求的个数进行的，但并没有考虑到另一个非常关键的问题，就是请求的大小。我在负载均衡里曾提过到这个问题，就是负载均衡算法基本上都没有考虑请求所需的资源。同理在限流算法也是如此

限流是针对请求个数进行的，那么显然，如果有两台实例，一台实例处理的都是小请求，另一台实例处理的都是大请求，那么都限流在每秒 100 个请求。可能第一台实例什么问题都没有，而第二台实例就崩溃了

所以如果面试官问到为什么使用了限流，系统还是有可能崩溃，或者你在负载均衡里面聊到了请求大小的问题，都可以这样来回答，关键词是**请求大小**

- 限流和负载均衡有点儿像，基本没有考虑请求的资源消耗问题。所以负载均衡不管怎么样，都会有偶发性负载不均衡的问题，限流也是如此。例如即便我将一个实例限制在每秒 100 个请求，但是万一这个 100 个请求都是消耗资源很多的请求，那么最终这个实例也可能会承受不住负载而崩溃。动态限流算法一定程度上能够缓解这个问题，但是也无法根治，因为一个请求只有到它被执行的时候，我们才知道它是不是大请求

以上就是我们在回答限流相关问题时的基本思路，如果可以回答出来，基本上就可以拿到一个 70 分的成绩，你满意吗？相信你和我一样，还想要更加出类拔萃一点，那这时候就要从计算阈值上面下功夫了

### 计算阈值

在面试限流的基本回答里面，你已经主动提起了限流阈值难以确定。那么不出所料，面试官就会问你怎么确定阈值。又或者你使用了限流的不同案例，那么面试官也会问你限流的阈值是怎么确定的

总体上思路有四个

- **看服务的观测数据**
- **压测**
- **借鉴**
- **手动计算**

看服务的性能数据属于常规解法，基本上就是看业务高峰期的 QPS 来确定整个集群的阈值。如果要确定单机的阈值，那就再除以实例个数。所以你可以这样来回答，关键词是
**业务性能数据**

- 我们公司有完善的监控，所以我可以通过观测到的性能数据来确定阈值。比如说观察线上的数据，如果在业务高峰期整个集群的 QPS 都没超过 1000，那么就可以考虑将阈值设定在1200，多出来的 200 就是余量
- 不过这种方式有一个要求，就是服务必须先上线，有了线上的观测数据才能确定阈值。并且，整个阈值很有可能是偏低的。因为业务巅峰并不意味着是集群性能的瓶颈。如果集群本身可以承受每秒 3000 个请求，但是因为业务量不够，每秒只有 1000 个请求，那么我这里预估出来的阈值是显著低于集群真实瓶颈 QPS 的

注意你在回答的时候也解释了这种方法的缺陷，这算是一个小亮点。然后我们可以继续讨论其他的思路，关键词是**压测**

- 不过我个人觉得，最好的方式应该是在线上执行全链路压测，测试出瓶颈。即便不能做全链路压测，也可以考虑模拟线上环境进行压测，再差也应该在测试环境做一个压力测试

在这个回答里面你其实已经回答出了最正确的思路：做压测，而且你要强调全链路压测。理由很简单，限流针对的是线上环境，那么自然要尽可能模拟线上环境。最符合这个要求的就是全链路压测了，它就是直接在线上环境执行的，因此结果也是最准的

然后你需要进一步解释，怎么利用压测结果。大部分性能测试的结果类似于图片里展示的这样，当然你是不太可能搞出来那么优雅的图形，多少会有些偏差

从理论上来说，你可以选择 A、B、C 当中的任何一个点作为你的限流的阈值

- A 是性能最好的点。A 之前 QPS 虽然在上升，但是响应时间稳定不变。在这个时候资源利用率也在提升，所以选择 A 你可以得到最好的性能和较高的资源利用率
- B 是系统快要崩溃的临界点。很多人会选择这个点作为限流的阈值。这个点响应时间已经比较长了，但是系统还能撑住。选择这个点意味着能撑住更高的并发，但是性能不是最好的，吞吐量也不是最高的
- C 是吞吐量最高的点。实际上，有些时候你压测出来的 B 和 C 可能对应到同一个 QPS 的值。选择这个点作为限流阈值，你可以得到最好的吞吐量

![](image/Pasted%20image%2020250220035332.png)

你在回答怎么选之前，最好给面试官比划一下上面这张图中的三条曲线，然后解释这三个点，口诀就是**性能 A、并发 B、吞吐量 C**

- 综合来说，如果是性能苛刻的服务，我会选择 A 点。如果是追求最高并发的服务，我会选择 B 点，如果是追求吞吐量的服务，我会选择 C 点

面试官多半会杠你，压力测试特别难，或者有些服务根本测不了，那你怎么办。这个时候，你需要说点正确但没用的废话，关键词**压测是基操**。你在表述的时候语气要委婉，态度要坚决

- 一般我会认为一家公司应该把压测作为提高系统性能和可用性的一个关键措施，毕竟没有压测数据，性能优化和可用性改进也不知道怎么下手。所以我还是比较建议尽可能把压测搞起来，反正压测这个东西是迟早要有的

然后你就要转过话头，顺着面试官的话往下说，讨论真的做不了压测的时候怎么确定阈值，关键词就是**借鉴**

- 不过如果真的做不了，或者来不及，或者没资源，那么还可以考虑参考类似服务的阈值。比如说如果 A、B 服务是紧密相关的，也就是通常调用了 A 服务就会调用 B 服务，那么可以用 A 已经确定的阈值作为 B 的阈值。又或者 A 服务到 B 服务之间有一个转化关系。比如说创建订单到支付，会有一个转化率，假如说是 90%，如果创建订单的接口阈值是 100，那么支付的接口就可以设置为 90

![](image/Pasted%20image%2020250220035625.png)

这个时候面试官可能会继续问：如果我这是一个全新的业务呢？也就是说，你都没得借鉴。这个时候就只剩下最后一招了**手动计算**

- 实在没办法了，就只能手动计算了。也就是沿着整条调用链路统计出现了多少次数据库查询、多少次微服务调用、多少次第三方中间件访问，如 Redis，Kafka 等
- 举一个最简单的例子，假如说一个非常简单的服务，整个链路只有一次数据库查询，这是一个会回表的数据库查询，根据公司的平均数据这一次查询会耗时 10ms，那么再增加 10 ms 作为 CPU 计算耗时。也就是说这一个接口预期的响应时间是 20ms。如果一个实例是 4 核，那么就可以 $1000ms {\div} 20ms \times 4 = 200$ 得到阈值

这个时候你还可以进一步补充一些手动计算要考虑的事情

- 手动计算准确度是很差的。比如说垃圾回收类型语言，还要刨除垃圾回收的开销，相当于 200 打个折扣。折扣多大又取决于你的垃圾回收频率和消耗

最后再升华一下主题

- 最好还是把阈值做成可以动态调整的。那么在最开始上线的时候就可以把阈值设置得比较小。后面通过观测发现系统还很健康，就可以继续上调阈值

### 总结

讨论了限流的主要问题，包括限流算法，限流对象以及限流之后的做法，在讨论怎么计算阈值的问题时，你尤其要记住里面提到的思路。不仅仅是面试中，在你实际工作中也用得上的。


再次强调一下，你应该在面试前尽可能在公司里面应用一下限流，同时尝试做一做压测。如果公司没有这种压测的环境，那么这正好是你刷 KPI 的机会。你把压测环境准备好，流程标准化之后，这件事情本身也可以作为你面试时候的一个亮点

![](image/Pasted%20image%2020250220040253.png)

## 思考题

针对 IP 限流是一个非常常见的限流方案，那么怎么获得用户的 IP 呢？尤其是在请求经过了网关的情况下，怎么避免自己拿到的是网关的 IP

-  使用标准 HTTP 头中的 `X-Forwarded-For`
	- 很多网关（例如 Nginx、Apache、Traefik）在转发请求时，会将用户的真实 IP 放入 `X-Forwarded-For` 头中
	- 格式通常是 `X-Forwarded-For: 用户IP, 中间代理IP, 网关IP`
	- 取该头的第一个 IP，即为客户端的真实 IP
- 利用 TCP Options 的字段来承载真实源 IP 信息、Proxy Protocol、NetScaler 的 TCP IP header
- 隧道 +DSR 模式


我在阈值里面提到的 ABC 三个点，你能说出你的业务应该使用哪个点

- 需要根据系统的整体情况来考虑
	- 如果系统很少会触发阈值，可以考虑 B 点，追求最大并发数。触发限流之后，系统一般阻塞下，扛一扛就过去了
	- 如果系统长时间在阈值附近徘徊，说明系统性能已经接近极限了，就算把请求阻塞下，最后多半也是超时。这个时候选 C 点更好，最大吞吐量，能处理掉最多的请求
	- 如果系统对性能要求苛刻，比如整条链路超时时间很短，那就只能选 A 点，最大化性能。但凡请求的响应时间长一点，可能就整体超时了

# 隔离

 隔离和前面讨论的熔断、降级、限流比起来，在面试中要“冷”一点。一个很重要的原因是隔
离在实际中的应用要比限流这种措施少很多。尤其是在中小型公司，很多时候是用不到隔离
的。但隔离依旧是构建高可用和高性能的微服务架构中的一环，因为在**出现故障的时候，隔离以把影响限制在一个可以忍受的范围内**

比如说我们为 VIP 用户提供单独的服务集群，普通用户共享一个服务集群。那么普通用户集群
出了问题，VIP 用户一点感觉都没有，依旧可以正常使用，这样就可以保证 VIP 用户体验不受
损。特别是复杂的、核心的和规模庞大的服务，隔离机制就更加重要了。否则，一个小小的故
障都能蔓延到整个系统，你就离喜提大礼包不远了

所以今天我就带你看看隔离在实际工作中形形色色的用法以及两个比较出彩的隔离方案

## 介绍

隔离是通过资源划分，在不同服务之间建立边界，防止相互影响的一种治理措施

隔离在实际工作中有很多种做法，从不同的角度可以进行不同类型的隔离。一般来说，使用隔离策略主要是为了达到 3 个目的

- **提升可用性**
	- 也就是说防止被影响或防止影响别人。这部分也叫做故障隔离
- **提升性能**
	- 这是隔离和熔断、降级、限流不同的地方，一些隔离方案能够提高系统性能，而且有时候甚至能做到数量级提升
- **提升安全性**
	- 也就是为安全性比较高的系统提供单独的集群、使用更加严苛的权限控制、迎合当地的数据合规要求等

一般的原则是**核心与核心隔离，核心与非核心隔离**，注意，这里有一个常见的误解，很多人认为核心服务可以放在一起，实际上并不是

举例来说，如果核心服务都放在同一台机器上，那么这台机器一宕机，所有的核心服务就都宕机了。反过来说，如果核心服务部署在了不同的机器上，那么其中一台机器宕机了，也就只有这台机器上的服务崩了，而其他机器上的服务还是可以继续运行

![](image/Pasted%20image%2020250220052937.png)

那么隔离究竟该怎么样做才能达成提升可用性、提升性能和提升安全性的目标呢？其实可以采取的措施也是非常多的，让我们一个个看

## 机房隔离

机房隔离也就是我们会把核心业务单独放进一个机房隔离，不会和其他不重要的服务混在一起。这个机房可能会有更加严格的变更流程、管理措施和权限控制，所以它的安全性会更高

一些公司的金融支付业务，个人隐私类的往往会有独立的机房，或者至少在逻辑上它们会有完全不同的安全策略和保护措施。还有一些公司受制于当地的法律法规，例如数据必须留在本地。那么这些公司也只能说一个国家或一个地区一个机房

![](image/Pasted%20image%2020250220053116.png)

在这种形态下，其中一个机房崩溃了自然不会对另外一个机房有任何影响

机房隔离和多活看起来有点儿像，但是从概念上来说差异还是挺大的。这里的隔离指的是不同服务分散在不同的机房，而多活强调的是同一个服务在不同的城市、不同的机房里面有副本

![](image/Pasted%20image%2020250220053135.png)

## 实例隔离

实例隔离是指某个服务独享某个实例的全部资源。当然这里指的是常规意义上的实例，比如说你在云厂商里面买了一个 4C8G 的机器，实例隔离就是指服务独享了这个实例，没有和其他组件共享

但是这种隔离并没有考虑到这么一种情况，就是虽然你买了很多实例，但是这些实例在云厂商那里都是同一个物理机虚拟出来的。这种情况下，如果物理机有故障，那么这些虚拟机都会出问题

![](image/Pasted%20image%2020250220053243.png)

在早期还没有云服务的时候，也有机器隔离的说法。它指的就是核心服务独享一整个物理机的资源

在一些小公司里面，为了节省成本，一些不太重要的服务就可能会共享同一个实例，特别是测试环境，经常在一台机器上部署多个服务，如果一个服务消耗资源过多，比如说把 CPU 打满，所有人的测试服务就都跟着崩了

![](image/Pasted%20image%2020250220053309.png)

而同一个服务的实例合并在一起就构成了集群，那么这个集群自然也是隔离的

## 分组隔离

分组隔离其实就是典型的微服务框架分组功能的应用。它通常是指一起部署的服务上有多个接口或者方法，那么就可以利用分组机制来达成隔离的效果

- B 端一个组，C 端一个组
- 普通用户一个组，VIP 用户一个组
- 读接口一个组，写接口一个组
	- 这种也叫做读写隔离。比如说在生产内容的业务里面，没有实行制作库和线上库分离的话，那么就可以简单地把读取内容划分成一个组，编辑内容划分成另外一个组
- 快接口一个组，慢接口一个组
	- 这个和前面的读写隔离可能会重叠，因为一般来说读接口就是比较快

分组隔离非常灵活，你完全可以根据自己的实际业务来设计不同的隔离策略

![](image/Pasted%20image%2020250220053427.png)

## 连接池隔离和线程池隔离

这两种都可以看作是池子隔离，只不过一个池子里面放的是连接，另一个池子里面放的是线程。而且连接池和线程池都不必局限在微服务领域，例如数据库连接池也是同样可以做隔离的

这两种措施针对的是同一个进程内的不同服务，一般的做法都是给核心服务单独的连接池和线程池。这么做对于性能的改进也是很有帮助的，尤其是连接池隔离

![](image/Pasted%20image%2020250220053632.png)

线程池隔离在 Java 里面被广泛使用，而在另外一些语言里面则根本没有线程池隔离的概念。比如说 Go 语言，虽然 Go 存在所谓的 GMP 调度，里面有线程的概念，但是开发者是操作不了线程的

![](image/Pasted%20image%2020250220053705.png)

那么在 Go 这种语言里面有没有类似的策略呢？理论上来说，可以做协程隔离，但是就我对大多数框架的了解，它们都没有提供类似的功能。毕竟协程过于廉价了，似乎不太值得做池化。但是在后面慢任务隔离的案例里面，你可以看到协程池隔离在一些场景下还是有必要的

与这两个类似的还有进程隔离，顾名思义它是指为不同的服务或者业务准备独立的进程。这种措施在 PHP 里面更加常见。另外有一种说法是认为容器化本身也属于进程隔离的一种，那么这么看起来，在云原生时代进程隔离就算是应用最广泛的隔离策略了

## 第三方依赖隔离

第三方依赖隔离是指为核心服务或者热点专门提供数据库集群、消息队列集群等第三方依赖集群

![](image/Pasted%20image%2020250220053828.png)

正常来说，越是关键的业务，业务上越是关键的路径，就越要小心隔离。比如说我们经常听到某家公司因为 Redis 共用，导致某个业务把 Redis 搞崩了，结果其他更加重要的服务也一起崩溃了的事故报告

## 面试准备

首先要记住刚刚我列举的这些策略，然后你要考虑这些策略能不能用在你维护的服务里面。如果能，但是你还没有做，那么你就可以在面试的时候说你计划将来用隔离来保护你的服务

其次要弄清楚隔离机制在你们公司的应用情况，例如你可以从以下这些方面去了解

1. 数据库方面：你们公司有几个物理上的数据库（包括主从集群），有没有业务是独享某一个物理数据库
2. 你们公司有没有准备多个 Redis 实例或者多个集群。另外理论上来说开启了持久化功能或者被用作消息队列的 Redis 最好是一个独立的集群，防止影响正常将 Redis 用作缓存业务
3. 其他类似的中间件，包括消息队列、Elasticsearch 等，是否针对不同业务启用了不同集群
4. 对核心业务、热点业务在资源配置上有没有什么特别之处
5. 在业务上，有没有针对高价值用户做什么资源倾斜
6. 在具体的系统上，有没有使用连接池隔离、线程池隔离等机制
7. 因为缺乏隔离机制引起的事故报告

![](image/Pasted%20image%2020250220054111.png)

其实现实中还有因为组织关系引起的隔离。比如说你们公司 A 部门和 B 部门各自有独立的 Redis 集群，但这并不是出于隔离的目的有意设计的，而是纯粹因为两个部门的利益冲突才各自维护了一个 Redis 集群。这一点你要注意区分

隔离最佳的面试策略是**把隔离作为你构建高可用和高性能微服务的手段之一**，和熔断、降级、限流合并在一起作为一个方案

如果面试官问到了微服务架构可用性和性能的问题，那么隔离都可以作为你的回答。如果前面你已经讨论到了熔断、降级、限流中的任何一种，这里都可以顺带提起隔离

除此之外，通过下面这些问题把话题引导到隔离

- 连接池和线程池相关的问题
	- 你可以把隔离作为例子，证明你在连接池和线程池的使用上是很有心得体会的
- 如何处理热点
	- 你可以回答隔离，一方面可以提升性能，另一方面可以防止热点被别的业务影响，同时也可以防止别的业务影响到热点
- 某个第三方中间件，比如 Redis 崩溃之后怎么办
	- 你可以强调给核心业务不同的 Redis 集群，能够一定程度上缓解这个问题，毕竟只要核心业务的 Redis 没有崩溃，不重要的业务的 Redis 崩溃也不是那么难以接受

### 基本思路

不管是面试官直接问隔离，还是问到如何提高微服务可用性，你都可以列举前面提到的那些隔离措施。要注意，为了方便面试官理解，你需要尽可能举例子，最好是用你们公司的例子

这里我给你提供一个例子，你可以参考，关键词是BC 端隔离

- 之前为了保障我们 C 端用户的服务体验，我在我们的服务上利用微服务框架的分组功能做了一个简单的隔离。我们的服务本身部署了八个实例，我将其中三台实例分组为 B 端。于是商家过来的请求就只会落在这三台机器上，而 C 端用户的请求就可以落到八台中的任意一台。我这么做的核心目的是限制住 B 端使用的资源，但是 C 端就没有做任何限制

如果你收集到了一些因为缺乏隔离机制而引起的事故报告，那么你可以进一步讲述这些案例。这里我用 Redis 来举一个例子，关键词是**大对象**

- 之前我在公司的时候就遇到过一个事故。当时我们的服务原本运行得很好，结果突然之间 Redis 就卡住了，导致我们的 Redis 请求大部分超时，请求都落到了数据库上，数据库负载猛增，导致数据库查询也超时。后来运维排查，确认了 Redis 在那段时间因为别的业务上线了一个新功能，这个功能会批量计算数据，产生的结果会存储在 Redis。但是这个结果非常庞大，所以在这个功能运行的时候，Redis 就相当于在频繁操作大对象
- 也不仅仅是我们，所有使用那个 Redis 的业务都受到了影响。后来我们再使用 Redis 的时候，就分成了核心与非核心。核心 Redis 有更加严格的接入机制和代码 review 机制，而非核心的就比较随意。不仅如此，我们还为高并发的服务设计了数据库限流，防止再来一次 Redis 失效导致 MySQL 被打崩的事故

![](image/Pasted%20image%2020250220054534.png)

可以注意到，我在最后还补充了一段使用限流来保护数据库的话，那么这就可以将话题带到限流那边

- 熔断
- 降级
- 限流
- 隔离

这些保证微服务的高可用措施并不是互相割裂了，任何问题的解法也不是单一的，你需要将这几种手段内化于心，融会贯通，达到收缩自如的效果

好了，我们前面一直在说隔离的方式还有它能达到的目标，那隔离就没有什么缺点了吗？当然有，关键词就是**贵且浪费**

- 隔离本身并不是没有代价的
	- 一方面，隔离往往会带来资源浪费。例如为核心业务准备一个独立的 Redis 集群，它的效果确实很好，性能很好，可用性也很好。但是代价就是需要更多钱， Redis 本身需要钱，维护它也需要钱
	- 另外一方面，隔离还容易引起资源不均衡的问题。比如说在连接池隔离里面，可能两个连接池其中一个已经满负荷了，另外一个还是非常轻松。当然，公司有钱的话就没有什么缺点了

这一段内容你可以在整个隔离面试快要结束的时候补充上。做完前面这些工作，我们的基本操作就完成了

### 亮点方案

前面的只是基本操作。如果想让自己的回答更加出彩，肯定少不了亮点的加持。我在这里给出两个亮点方案

1. 慢任务隔离，
2. 制作库与线上库分离

你可以考虑选择其中一个在面试中使用

#### 慢任务隔离

这个案例本质上就是**线程池隔离**。我相信你在实际工作中也会经常遇到类似的场景。其中有两种很常见的场景，我们会考虑开启一个线程池来处理

- 异步任务，比如说收到请求之后直接返回一个已接收的响应，而后往线程池里面提交一个任务，异步处理这个请求
- 定时任务，比如说每天计算一下热榜等

这一类场景有一个潜在的隐患，就是**慢任务可能把所有的线程都占掉**。我举一个极端的例子，假如说我线程池里最多有 100 个线程，而绝大多数任务在一秒内就可以执行完毕

如果说某一个时刻，来了 100 个至少需要一分钟的慢任务，这 100 个慢任务就会占据全部的线程，那么其他普通的任务全都得不到执行

![](image/Pasted%20image%2020250220054947.png)

所以要解决这种问题，就是要考虑甄别出慢任务之后，将这些任务丢到一个单独的线程池里

- 之前我们遇到过一个 Bug，就是我们的定时任务总不能及时得到调度。后来我们加上监控之后，发现是因为存在少数执行很慢的任务，将线程池中的线程都占满了。所以我后来引入了线程池隔离机制，核心就是让慢任务在一个专门的线程池里面执行
- 我准备了两个线程池，一个线程池专门执行慢任务，一个是执行快任务。而当任务开始执行的时候，先在快任务线程池里执行一些简单的逻辑，确定任务规模，这一步也就是为了识别慢任务。比如说根据要处理的数据量的大小，分出慢任务。如果是快任务，就继续执行。否则，转交给慢任务线程池

![](image/Pasted%20image%2020250220055025.png)

你可以进一步补充如何识别慢任务，关键词是**时长数据量**

- 这种方案的关键是如何识别慢任务。最简单的做法就是如果运行时间超过了一个阈值，那么就转交给慢任务线程池。这在识别循环处理数据里面比较好用。只需要在每次进入循环之前检测一下执行时长就可以了。而其他情况比较难，因为你没办法无侵入式地中断当前执行的代码，然后查看执行时长
- 另外一种方案是根据要处理的数据量来判断。比如说任务是找到数据库里面符合条件的数据，然后逐条处理。那么可以先统计一下数据库有多少行是符合条件的。如果数据量很多，就转交给慢任务处理

这里我用线程来举的例子，但如果你用的是 Go 语言，那么你可以用协程来替换线程。虽然我在前置知识里面说协程太便宜以至于大家很少用协程池，但并不代表没有协程池。那么在这个场景下你应该能够看到协程池存在的必要性了

此外这里还有一个可能被面试官问到的问题**业务中断**，业务中断只能依赖于人在业务代码里面嵌入检测代码，无法做到自动化、智能化检测并中断。你会超时控制里再次见到这个问题

#### 制作库与线上库分离

在正常的内容生产平台或者电商平台，一般都会有制作库和线上库的概念。我这里就用内容生产平台来作为例子

当创作者正在创作的时候，他们的文章、视频等内容是存放在制作库的。等到他们完成创作之后，点击发布的时候，就会保存到线上库。当然现实中从制作库到线上库的步骤并不是那么简单的。比如说内容生产平台都需要经过审核之后才能真正发布到线上库

![](image/Pasted%20image%2020250220055211.png)

并且因为本身线上库的数据是只有在制作库同步的时候才会变更，所以缓存可以做得更加细致。比如说在真正发布的时候，就直接同步写入到缓存。这样阅读请求会直接命中缓存，就不需要回表了

在电商领域，这个过程可能是商家修改商品信息而后发布，在金融领域可能是录入金融方案再发布。基本上一端在生产信息，另外一端在查看信息的业务，都可以用这个架构来提高可用性和性能

所以你可以参考这个方案来介绍你类似的业务

- 在我们的业务里面，采用了制作库和线上库分离的方案来保证业务的可用性和性能。大体来说，作者在 B 端写作，操作的都是制作库，这个过程 C 端读者是没有任何感知的。当作者点击发布之后，就会开始同步给审核，审核通过之后就会同步给线上库。在同步给线上库的时候，我们还会直接同步到缓存，这样作者的关注者阅读文章的时候就会直接命中缓存
- 后面如果作者要修改文章，修改的也是 B 端制作库，等他修改完毕，就会再次提交审核。审核完成之前，C 端用户看到的都是历史版本，这样 B 端和 C 端隔离保证了两边的用户体验。同时拆成两个数据库之后，C 端线上库几乎都是读流量，性能很好

如果你的公司有类似的业务但是还没有引入这个这种方案，那么也可以考虑在公司内部重构一下，加深理解

### 总结

这节课我们讨论了常见的隔离方案，分别是

- 机房隔离
- 实例隔离
- 分组隔离
- 连接池隔离和线程池隔离
- 第三方依赖隔离

并且给出了两个方案

- 慢任务隔离
- 制作库与线上库分离

慢任务隔离可以增加系统的稳定性，避免因为线程问题影响系统中的其他任务，而制作库与线上库分离的方式可以保证信息生成端和信息查看端的性能和体验

在实际工作中有很多类似的业务场景，如果你已经有类似的案例了，那么你就采用你的案例来说明问题

如果你还没有案例，那么你可以考虑在公司里面实施一波，实践过后相信你会有更深的体会

我在基本面试思路里面强调了你应该在最后补充一下隔离的缺点，这也算是一个面试技巧。即不管你是在讲自己的方案、同事的方案，还是你和面试官在讨论业界的某个方案，都不要只讲好处不讲缺点。最佳的策略是讲完优点讲缺点，讲完缺点讲改进。例如你在介绍自己的某个解决方案的时候就可以用这个模板

![](image/Pasted%20image%2020250220055548.png)

![](image/Pasted%20image%2020250220055553.png)

## 思考题

在分组功能里面我举了几个例子，那么如果热点的放一组，非热点的放一组，你觉得可不可行？为什么？

- 热点数据不能集中放，因为热点数据一般的请求量很大，需要将热点数据均衡分配各个节点，降低热点数据造成的压力
- 热点数据应该是比较重要的数据，如果出了问题，舆论影响会比较大。热点数据可以通过负载策略打到权重高的机器。热点数据只是说查询频繁，不是大请求，所以按照冷热分离解决不了本质的问题。

连接池隔离虽然很厉害，但是很多微服务框架并不支持连接池隔离。那么你用的微服务框架支持吗？你可以分析一下原因

- 在对接新服务并且是核心业务的时候会使用线程池隔离，原因：新服务一般稳定性差，不能影响核心业务。当然用的多了，到处都是线程池，增加线程切换和内存的消耗
- 这时候，如果我是面试官我就会追问你，那么多线程池你怎么管？也就是你提到的，到处都是线程池有什么问题？怎么解决问题？
- 比如说我们之前就出过一个问题。也就是我们一个庞大的服务，每一个开发都觉得自己的业务很核心，然后就开了一个独立的线程池。本来每个人都开是没什么问题的，但是大家都开加一起就出问题了。不过当时我们也没很好的办法。一个是将这个庞大的服务拆分了；另外一个是梳理了一下，对服务进行了分级，分成了三级：独享，部分共享，全服务无共享三种线程池。这样控制住了线程池数量和线程数量。其实，超时控制的内容也可以用于缓解这个问题。就是设置好超时时间，那么线程池的线程会及时释放，变相地就可以少用一些线程，也能缓解系统线程数量过多的问题
- 彻底解决，还是依赖于当时我们直接拆分，一次拆出来三个核心服务，各自独立部署

# 超时控制

和前面我们讲的熔断、限流、降级和隔离一样，超时控制也是构建高可用系统的一环，因为它**能够节省系统资源，提高资源的有效利用率**

一般在面试的时候，关于超时控制，被问得最多的问题就是调用某个接口时的超时时间是多
长，以及你为什么认为这个超时设置是合理的。一般我们都能给出一个差不多的回答，不过如果你能够在超时控制的话题下稍微深入一点，比如聊一聊监听超时时间、链路超时控制，那你绝对能成为所有候选人中最靓的仔

所以今天我就带你来了解超时控制的方方面面，同时会给出全链路超时控制方案，让你在面试中更加出彩

## 介绍

超时控制是一个非常简单的东西，它是指在规定的时间内完成操作，如果不能完成，那么就返回一个超时响应

和超时控制有关的内容，你需要记住以下几点

- 超时控制的目标或者说好处
- 超时控制的形态
- 如何确定超时时间，这会是一个面试热点
- 超时之后能不能中断业务
- 谁来监听超时时间

## 超时控制目标

超时控制有两个目标

- 一是**确保客户端能在预期的时间内拿到响应**。这其实是用户体验一个重要理念“坏响应也比没响应好”的体现

![](image/Pasted%20image%2020250220174323.png)

- 二是**及时释放资源**。这其中影响最大的是线程和连接两种资源
	- 释放线程：在超时的情况下，客户端收到了超时响应之后就可以继续往后执行，等执行完毕，这个线程就可以被用于执行别的业务。而如果没有超时控制，那么这个线程就会被一直占有。而像 Go 这种语言，协程会被一直占有
	- 释放连接：连接可以是 RPC 连接，也可以是数据库连接。类似的道理，如果没有拿到响应，客户端会一直占据这个连接

**及时释放资源是提高系统可用性的有效做法**，现实中经常遇到的一类事故就是因为缺乏超时控制引起了连接泄露、线程泄露

![](image/Pasted%20image%2020250220174548.png)

## 超时控制形态

超时控制从形态上来看分成两种

- 调用超时控制，比如说你在调用下游接口的时候，为这一次调用设置一个超时时间
- 链路超时控制，是指整条调用链路被一个超时时间控制。比如说你的业务有一条链路是 A 调用 B，B 调用 C。如果链路超时时间是 1s，首先 A 调用 B 的超时时间是 1s，如果 B 收到请求的时候已经过去了 200ms，那么 B 调用 C 的超时时间就不能超过 800ms

链路超时控制在微服务架构里面用得比较多，一般在核心服务或者非常看重响应时间的服务里面采用

![](image/Pasted%20image%2020250220174644.png) 

比如说大厂的 App 首页接口响应时间都有硬性规定。就像某司的要求是 50ms，也就是说不管你后端多复杂，不管你后面调用多少个服务，你的响应时间都必须控制在 50ms 以内。我后面会再深入讨论这个问题，它是你刷亮点的关键

## 确定超时时间

确定超时时间是一个我们在面试中经常碰到的问题，常见的 4 种确定超时时间的方式是

- 根据用户体验来确定
- 根据被调用接口的响应时间来确定
- 根据压测结果来确定
- 根据代码来确定

超时时间要设置合理，过长可能会因为资源释放不及时而出事故，过短可能调用者会频繁超时，业务几乎没有办法执行

### 根据用户体验

一般的做法就是根据用户体验来决定超时时间。比如说产品经理认为这个用户最多只能在这里等待 300ms，那么你的超时时间就最多设置为 300ms

但如果仅仅依靠用户体验来决定超时时间也是不现实的，比如说当你去问产品经理某个接口对性能要求的时候，他让你看着办。那么这个时候你就要选择下一种策略了

![](image/Pasted%20image%2020250220200206.png)

### 根据响应时间

在实践中，大多数时候都是根据被调用接口的响应时间来确定超时时间。一般情况下，你可以选择使用 **99 线**或者 **999 线**来作为超时时间

所谓的 99 线是指 99% 的请求，响应时间都在这个值以内。比如说 99 线为 1s，那么意味着 99% 的请求响应时间都在 1s 以内。999 线也是类似的含义

但是使用这种方式要求这个接口已经接入了类似 Prometheus 之类的可观测性工具，能够算出 99 线或者 999 线。如果一个接口是新接口，你要调用它，而这时候根本没有 99 线或者 999 线的数据。那么你可以考虑使用压力测试

![](image/Pasted%20image%2020250220200259.png)

### 压力测试

简单来说，你可以通过压力测试来找到被调用接口的 99 线和 999 线。而且压力测试应该尽可能在和线上一样的环境下进行。但是就像我在限流里面提到的，很多公司其实内部没有什么压测环境，也不可能让你停下新功能开发去做压力测试。那么就无法采用压力测试来采集到响应时间数据

所以你就只剩下最后一个手段，根据代码来计算

### 根据代码计算

根据代码计算和我在限流里面讲的差不多。假如说你现在有一个接口，里面有三次数据库操作，还有一次访问 Redis 的操作和一次发送消息的操作，那么你接口的响应时间就应该这样计算

$$
接口的响应时间 = 数据库响应时间 × 3 + Redis响应时间 + 发送消息的响应
$$

如果你觉得不保险，那么你可以在计算出来的结果上再加一点作为余量。比如说你通过分析代码认为响应时间应该在 200ms，那么你完全可以加上 100ms 作为余量。你可以告诉这个接口的调用者，将超时时间设置为 300ms

## 超时中断业务

在面试的时候，还有一个值得和面试官深入讨论的问题 **超时中断业务**。所谓的中断业务是指，当调用一个服务超时之后，这个服务还会继续执行吗

答案是基本上会继续执行，除非服务端自己主动检测一下本次收到的请求是否已经超时了

举例来说，如果你的业务逻辑有 A、B、C 三个步骤。假如说你执行到 B 的时候超时了，如果你的代码里面没有检测到，那么还是会继续执行 C。但是如果你**主动**检测了超时，那么你就可以在 B 执行之后就返回

![](image/Pasted%20image%2020250220201012.png)

但是正常在实践中，我们是不会写这种手动检测的繁琐代码的。所以经常出现一个问题，就是客户端虽然超时了，但是实际上服务端已经执行成功了

你可以看一下我给出的这张示意图，用户第一次提交注册的时候拿到了超时响应，但是实际上他注册成功了，数据库写入了注册信息。所以当他第二次尝试重试的时候，立刻遇到了重复手机号码的错误

![](image/Pasted%20image%2020250220201349.png)

不过如果中间件监听超时时间部分设计得好，它可以帮我们中断一些步骤

## 监听超时时间

在微服务框架里面，一般都是微服务框架客户端来监听超时时间。在一些特殊的微服务框架里面，框架服务端也会同步监听超时时间

![](image/Pasted%20image%2020250220201420.png)

框架客户端监听超时时间的情况下，如果在发起请求之前，就已经超时了，那么框架客户端根本不会发起请求，而是直接返回超时响应。这等于直接帮我们中断了业务的后续步骤

![](image/Pasted%20image%2020250220201439.png)

如果框架客户端已经发出了请求，之后触发了超时时间，那么框架客户端就会直接返回一个超时错误给应用代码。后续服务端返回了响应，框架客户端会直接丢弃

![](image/Pasted%20image%2020250220201529.png)

而框架服务端监听超时的情况下，如果在收到请求的时候就已经超时了，那么框架服务端根本不会调用服务端应用代码，而是直接给框架客户端返回一个超时响应

![](image/Pasted%20image%2020250220201543.png)

而如果在等待业务响应的时候触发了超时，框架服务端会立刻释放连接，继续处理下一个请求。那么当应用返回响应的时候，它会直接丢弃，不会再回写响应

![](image/Pasted%20image%2020250220201709.png)

所以你可以看出来不管是客户端根本不发请求，还是服务端根本不把请求转交给业务，都能够避免把资源花在没有意义的超时请求上。为什么超时请求没有意义呢？因为用户都已经看到超时的页面了，所以后端继续处理已经没有意义了

总体来说，监听超时时间这个知识点面试官还是不太容易能想到的，所以在面试的时候如果你能深入讨论一下这个问题，应该可以增加一些亮点

## 面试准备

前面我们讲到的超时控制的目标、两种形态以及确定超时时间的方法你都要记住。此外你要弄清楚公司内是怎么使用超时时间的，你可以收集一些资料

- 你所在公司的核心业务，尤其是 App 首页之类的，公司层面上的性能要求是什么？也就是说响应时间必须控制在多少以内，然后进一步了解有没有采用链路超时控制
- 你自己维护的服务调用下游的时候有没有设置超时时间，超时时间都是多长
- 数据库查询有没有设置超时时间
- 跟任何第三方中间件打交道的代码有没有设置超时时间
	- 例如查询 Redis，发送消息到 Kafka 等

然后你要注意在公司里面收集一些跟超时控制相关的事故报告。例如因为没有设置超时时间，导致数据库连接耗尽或者线程数量飙升等事故报告。这些事故报告你可以在面试的过程中用来解释超时控制的必要性，或者用来凸显你解决事故的能力

在面试前我们也需要提前设想一下，关于超时控制，面试官会问到哪些问题？我整理了一下最常见的几个问题，你也可以借助这几个问题回忆一下前面的几个知识点

![](image/Pasted%20image%2020250220202401.png)

如果你现在调用别的服务、第三方接口、中间件都没有设置任何超时时间，或者使用的是默认超时时间，那么你就可以尝试自己先手动设置一下超时时间。这也是为了加深你的印象，更好地把控细节

### 基本思路

大多数时候面试官可能就是随便问一下你在调用别的服务的时候有没有设置超时时间，那么你可以简单回答，关键词是**超时控制目标**

- 我会设置超时时间，一般来说设置超时时间是为了用户体验和及时释放资源。比如说我有一个接口是提供给首页使用的，整个接口要求的超时时间是不超过 100ms。这个 100ms 就是公司规定的，是从用户体验出发确定的超时时间

这一步，我们只是说了一个硬性规定 100ms 的例子，换句话说是从用户体验出发确定的 100ms。那么面试官就可能会追问：“如果公司没这种规定你怎么确定合理的超时时间呢？”。这时候你就可以回答之前提到的**确认超时时间的四种手段**

- 没有规定的话，最好的办法就是从用户体验的角度出发确定超时时间，这个可以考虑咨询一下产品经理。如果这个方式不行的话，就可以考虑根据被调用接口的响应时间，来确定调用者的超时时间。比如说我要调用 A 接口，如果 A 接口的 999 线是 200ms，那么我就可以把我这一次调用的超时时间设置成 200ms。除了 999 线，99 线也可以作为超时时间
- 如果我要调用的是一个新接口，没有性能数据，那么就可以考虑执行压测，然后根据结果选用 99 线或者 999 线。压测的结果也不仅仅可以用在这里，也可以用在限流那里。实在没办法，我们还可以根据代码里面的复杂操作来计算一个时间

在这个回答里面，面试官可能从两个角度继续深挖。第一个是 99 线和 999 线究竟选哪个比较好。那么你可以抓住关键词**可用性**来回答。

原则上是看公司的可用性要求，要求几个 9 就要几个 9。如果没有硬性规定，那么看 99 线和 999 线相差多不多。不多的话就用 999 线，多的话就用 99 线

第二个是面试官可能会把问题切换到限流相关的内容上，因为你这里提到了**限流**，所以需要做好被提问的心理准备

紧接着，你可以补一个因为超时控制设置不合理而出现的事故。这里我用一个数据库超时的例子，你可以参考，关键词是**数据库连接**

- 正常来说，对任何第三方的调用我都会设置超时时间。如果没有设置超时时间或者超时时间过长，都可能引起资源泄露。比如说早期我们公司就出现过一个事故，某个同事的数据库查询超时时间设置得过长，在数据库性能出现抖动的时候，客户端的所有查询都被长时间阻塞，导致连接池中的连接耗尽

你可以把这个案例替换成实际工作中发生的事故，它能够进一步说明超时控制在保障系统可用性中的作用

如果想要尽量避免这样的事故发生，更好地用超时保护我们的系统，那就需要一个更加周全的方案了，就是为我们的**系统接入链路超时控制**，这样做用户体验会更好

### 链路超时控制

链路超时控制就是我们今天的亮点方案，本身链路超时就是一个非常适合“一杆子”打到底的话题。也就是说从链路超时控制本身可以延伸出许多问题，所以你千万要记得做好话术引导。当面试官问你链路超时控制是什么的时候，你就可以先简单介绍链路超时的基本特征，关键词是**链路**

- 链路超时控制和普通超时控制最大的区别是链路超时控制会作用于整条链路上的任何一环。例如在 A 调用 B，B 调用 C 的链路中，如果 A 设置了超时时间 1s，那么 A 调用 B 不能超过 1s。然后当 B 收到请求之后，如果已经过去了 200ms，那么 B 调用 C 的超时时间就不能超过 800ms。因此链路超时的关键是**在链路中传递超时时间**

在最后一句话里面，你提到了传递超时时间，但是并没有说怎么传递超时时间，这就是给面试官追问的机会。如果面试官追问了，你可以这么回答，关键词是**协议头**

- 大部分情况下，链路超时时间在网络中传递是放在协议头的。如果是 RPC 协议，那么就放在 RPC 协议头，比如说 Dubbo 的头部；如果是 HTTP 那么就是放在 HTTP 头部。比较特殊的是 gRPC 这种基于 HTTP 的 RPC 协议，它是利用 HTTP 头部作为 RPC 的头部，所以也是放在 HTTP 头部的。至于放的是什么东西，就取决于不同的协议是如何设计的了

![](image/Pasted%20image%2020250220203626.png)

- gRPC 官网对超时字段的说明

![](image/Pasted%20image%2020250220203638.png)

在最后一句，你依旧留了一个小尾巴。这句话是引导向超时时间传递的值究竟是什么的问题。正常来说，在链路中传递的可以是**剩余超时时间**，也可以是**超时时间戳**

![](image/Pasted%20image%2020250220204009.png)

这两者是各有优缺点的。目前来说剩余超时时间用得比较多，一般是以毫秒作为单位传递一个数值。它的缺点是服务端收到请求之后需要减去网络传输时间，得到真正的超时时间

而超时时间戳则涉及到时钟同步的问题，不过大多数情况下时钟之间的差值都很小，和超时时间动辄几百毫秒比起来，不值一提。所以如果面试官感兴趣，你就继续回答，关键词是**剩余超时时间或超时时间戳**

- 一般超时时间传递的就两种：剩余超时时间或者超时时间戳。比如说剩余 1s，那么就用毫秒作为单位，数值是 1000。这种做法的缺陷就是服务端收到请求之后，要减去请求在网络中传输的时间。比如说 C 收到请求，剩余超时时间是 500ms，如果它知道 B 到 C 之间请求传输要花去 10ms，那么 C 应该用 500ms 减去 10 ms 作为真实的剩余超时时间。不过现实中比较难知道网络传输花了 10ms 这件事
- 而传递超时时间戳，那么就会受到时钟同步影响。假如说此时此刻，A 的时钟是 00:00:00，而 B 的时钟是 00:00:01，也就是 A 的时钟比 B 的时钟慢了一秒。那么如果 A 传递的超时时间戳是 00:00:01，那么 B 一收到请求，就会认为这个请求已经超时了
- 当然，正常来说时钟同步不至于出现那么大的偏差，大多数时钟偏差几乎可以忽略不计。不过在时钟回拨的场景下，还是会有问题。我之前听说不同云服务商之间的时钟同步问题比较严重，可能也需要注意

![](image/Pasted%20image%2020250220210957.png)

在这个回答里面，你提到了难以知道 10ms 的问题，那么面试官自然就会问你该怎么知道网络传输耗时 10ms。换句话来说，你怎么计算请求的网络传输时间。你就可以这样回答

- 计算网络传输时间最好的方式就是使用性能测试。在模拟线上环境的情况下，让客户端发送平均大小的请求到服务端，采集传输时间，取一个平均值作为网络传输时间。另外一个方式就是不管。比如说正常情况下，A 调用 B，A 和 B 都在同一个机房，网络传输连 1ms 都不用。相比我们超时时间动辄设置为几百毫秒，这一点时间完全可以忽略不计。不过万一服务涉及到了跨机房，尤其是那种机房在两个城市的，城市还离得远的，这部分时间就要计算在内

你还可以额外强调一下，性能测试要完全模拟线上环境，否则计算就会有偏差

- 性能测试一定要尽可能模拟线上环境，尤其是线上环境可能会有更加复杂的网关和防火墙设置，这部分也会影响传输速率

链路超时还有一个弊端，也是面试官经常问的，就是如果 A 调用 B，B 调用 C 的这条链路的超时时间设置为 1s，但是 B 这个服务的提供者就说自己是不可能在 1s 内返回响应的，那么该怎么办？

这时候你要坚持最正确的做法，要求 B **优化性能**

- 这个时候最好的做法是强制要求 B 优化它的性能。比如说产品经理明确说这条链路就是要在 1s 内返回，那么 B 就应该去优化性能，而不是在这里抱怨不可能在 1s 内返回。不过要是 A 本身超时时间可以妥协的话，那么 A 调大一点也可以

最后的妥协话术，就是想表达你并不是完全不通人情的。如果面试你的人是 CTO 之类的领导，那么他们可能会看重软技能，就会问你如何推动 B 优化性能。这方面你按照你们公司的跨部门合作流程来回答就可以

不过我还有一个不那么正统充满了人情世故的解决方案，你可以参考

- 可以考虑请 B 的维护者喝杯奶茶，吃顿小烧烤，基本上都能解决问题。实在不行，就只能走官方渠道，找领导和产品经理出面，去找 B 的维护者的上级。不过闹到这一步关系就会比较僵，还是优先考虑请奶茶小烧烤的方案

### 总结

现在我再来问你，怎么保证用户能够在 1 秒内拿到响应，你应该对答案了然于胸了吧？这也是我们这节课的主题超时控制的目标之一，也就是确保客户端能在预期的时间内拿到响应，保证用户的体验。此外超时控制还能通过在客户端或服务端监听超时时间来感应到系统超时，及时释放线程和连接，保证系统的可用性

而这个 1 秒又是怎么算出来的呢？实际上我们可以通过用户体验、响应时间、压力测试和根据代码计算这四种方式来确定具体的超时时间，不宜过长或过短，过长，会浪费客户端资源；过短，可能导致客户端无法处理响应

在实际的工作场景中，超时控制有调用超时控制和链路超时控制两种形态，而在微服务架构中链路超时控制比较常用。所以我们在亮点方案部分对链路超时控制进行了深入的讨论，你需要记住里面的几个关键词：**链路、协议头、剩余超时时间与超时时间戳**。你可以从这几个关键词出发，整理自己的思路

![](image/Pasted%20image%2020250220211311.png)

## 思考题

在根据被调用接口的响应时间来确定超时时间里面，我说可以使用 99 线或者 999 线来作为超时时间。那么平均响应时间和响应时间中位数，能不能作为超时时间

- 超时时间主要看的大部分请求的响应时间，一般情况下，都是选择T99或者T999。当然具体问题具体分析，要是当前业务有长尾效应，也可以取平均响应时间或者响应时间中位数

在监听超时那里，能不能只在服务端那边监听超时，而客户端完全不管

- 不能。服务端可以不管，客户端一定要管，因为请求经过网络，不一定会到达服务端，或者说到达服务端的时间不可控
- 客户端也需要监听是否超时，一般ToC的业务，客户端的请求要通过公网才能到达后端，公网的网络情况有很大未知性，不可控，也有一定的丢包率，所以在客户端监听超时，可以给客户更好的用户体验，另外也就将超时数据传回服务端，作为监控指标，方便后续优化

# 第三方接口

到目前为止，我们可以看到任何一个系统，都难免要跟第三方打交道

- 登录注册要跟微信开放平台打交道，接入扫码登录
- 金融要跟银行打交道，比如结算
- 重要功能发验证码，要跟短信服务商打交道
- 人脸识别、身份认证也要跟供应商打交道

![](image/Pasted%20image%2020250220230544.png)

所以早期我就注意到很多人的简历上都写了自己对接过这一类的 API。但是我还注意到大多数人对接这些 API 的时候只是简单实现了功能。换句话来说，就是完全没有考虑可用性和容错之类的问题

实际上，调用第三方接口是一个非常常见的场景，面试官很容易理解，所以在面试的时候你谈到这样的项目，很容易取得共鸣。而且你可以在上面应用非常多的微服务治理措施，和前面学过的内容形成呼应

所以今天我就来和你深入讨论一下，如果你需要调用一些第三方接口，而你难以推动这个第三方接口的提供者做一些事情的时候，如何保证你的系统高可用

## 介绍

正常来说，和第三方平台打交道的是一个独立的模块还是一个独立的服务，取决于你维护的是一个单体应用还是微服务应用

![](image/Pasted%20image%2020250220234457.png)

对于自己系统内这样一个第三方模块或者第三方服务来说，它要解决的问题也很直观

- 提供一个一致性抽象，屏蔽不同第三方平台 API 之间的差异
- 提供客户端治理，即提供调用第三方平台 API 的重试、限流等功能
- 提供可观测性支持
- 提供测试支持

## 一致性抽象

这算是你这个模块或者服务最基本的目标。举个例子，如果你调用的是第三方支付平台，你们公司支持多种接入方式，包括微信支付、支付宝支付

在这种情况下，业务方只希望调用你的某个接口，然后告诉你支付所需要的基本信息，比如说金额和方式。你这个接口的实现就能根据具体的支付方式发起调用，业务方完全不需要关心其中的任何细节

![](image/Pasted%20image%2020250220234644.png)

这种一致性抽象会统一解决很多细节问题。比如不同的通信协议、不同的加密解密算法、不同的请求和响应格式、不同的身份认证和鉴权机制、不同的回调机制等等。这会带来两个好处

1. 研发效率大幅提高，对于业务方来说他们不需要了解第三方的任何细节，所以他们接入一个第三方会是一件很简单的事情
2. 高可扩展性，你可以通过扩展接口的方式轻松接入新的第三方，而已有的业务完全不会受到影响

![](image/Pasted%20image%2020250220234805.png)

提供了一致性抽象之后，你就可以在这种一致性抽象上做很多事情，比如说客户端治理

## 客户端治理

前面我们在讲熔断、降级、限流的时候，实际上都是在服务端或者网关进行的。那么这一次你就需要在客户端进行治理了。一般来说，客户端治理有两个关键措施：**限流**和**重试**

就拿限流来说，大部分的第三方平台 API 为了保护自己的系统，是不允许你频繁发送请求的。比如说某些银行的接口只允许你一秒钟发送十个请求，多了就会拒绝服务。那么自然地，你其实可以在你发起调用之前就开启限流，这样就可以省去一次必然失败的调用

![](image/Pasted%20image%2020250220234920.png)

另外一个重要的措施是重试。当你调用第三方平台超时的时候，业务方肯定不希望你直接返回超时响应，因为他们还要自己处理超时，比如说发起重试等

![](image/Pasted%20image%2020250220235029.png)

所以你可以提供重试机制，并且可以对业务方保持透明。但你要小心的是，只有当第三方接口是幂等的时候你才能发起重试

当你完成客户端治理之后，一般是不会出问题的。但万一业务出问题了怎么办？这时候你就需要可观测性支持，告诉你的业务方你的接口稳如泰山，把锅甩出去

## 可观测性支持

第三方接口一般都不在你的控制范围内，所以你一定要做好监控，比如说接入 Prometheus 和 SkyWalking 等工具。同时，你还要考虑提供便利的查询工具，让你自己和你的业务方都能够快速定位问题

告警也是必不可少的。这些告警分成两类，一类是给你和你共同维护这个功能的同事使用的，另外一类是给业务方用的。例如，当监控系统发现第三方平台突然不可用了，那么它会发出两个告警，一个是告诉你出事了；另外一个则是通知业务方第三方平台目前不稳定，那么业务方就需要确认对他们业务的影响范围，以及他们是否需要启动一些容错措施

![](image/Pasted%20image%2020250220235327.png)

可观测性做得好，定位和解决问题就会变得很简单。但是能不能进一步降低一点出问题的概率呢

当然是可以的，你把测试支持做好，让你的业务方多测测，省得出了问题甩锅给你

## 测试支持

测试支持的核心是你要提供**mock 服务**。例如正常情况下，业务方调用你的接口，你会真的调用第三方 API。但是在测试环境下，你就要考虑返回 mock 响应

如果第三方平台还有回调机制，并且你在收到回调之后还要通知业务方，那么你还需要模拟这个回调。比如说微信支付接口后面会回调你的一个接口，告知你支付结果

![](image/Pasted%20image%2020250220235439.png)

使用 mock 服务有很多好处

- 没有额外开支。比如说发短信之类的，短信是收费的，那么测试服务如果能避免真的发送短信，多少也能省一点
- 不受制于第三方平台。有些第三方平台的认证和鉴权机制非常复杂，在测试环境要发起一次调用几乎不可能，那么只能用 mock 服
- 你可以返回业务方任何预期的响应，包括成功响应、失败响应，甚至于你还能返回模拟第三方平台超时的响应

如果考虑到压测之类的问题，那么这个 mock 功能就更加必不可少了，毕竟第三方是不可能配合你做压测的

## 面试准备

如果你的业务需要和第三方平台打交道，那么你需要了解清楚以下信息

- 你们是否构建了一个一致性的抽象，屏蔽了不同平台之间的差异？比如说你是和短信服务商打交道，如果你们公司决定换一家短信服务商，那么你需要做哪些事情，你的业务方能否不受影响
- 第三方平台有没有治理措施？比如说有没有限流机制，如果有是怎么限流的，你有没有针对这个限流做对应的客户端限流
- 你有没有在和第三方打交道的时候引入重试机制，以及重试几次，重试间隔如何，如果重试最终都失败了怎么办

面试调用第三方这个话题的最佳策略就是将它包装成你整个系统可用性的关键一环。所以在面试官问到可用性相关内容的时候，或者直接问你是怎么和第三方打交道的时候

![](image/Pasted%20image%2020250220235650.png)

### 基本思路

面试官有些时候不一定会想到要深入考察你和第三方打交道的内容，因为可能他们公司做得就比较差，所以你要考虑主动出击。这种主动出击和前面的熔断、降级、限流、超时控制差不多。比如说你在自我介绍或者在项目介绍的时候，强调一下你的系统是一个**高可用**的微服务架构

- 我的系统对可用性要求非常高，为此我综合使用了熔断、限流、降级、超时控制等措施。并且，我这个系统还有一个特别之处，就是它需要和很多第三方平台打交道。所以要想保证系统的可用性，我就需要保证和第三方打交道是高可用的

这种话术你已经在前面的内容里见过了。当你将自己的项目说成是高可用的项目的时候，那么面试官肯定会逮着你往死里问高可用，那么你就能将话题全方位展开，并且限定在自己熟悉的战场内

比如当你们聊到了调用第三方的时候，你可以考虑采用这个话术来介绍你的做法，关键词是**前后对比**

- 我在刚接手这个项目的时候，这一块的设计和实现不太行。总体来说可扩展性、可用性、可观测性和可测试性都非常差。为了解决这个问题，全方位提高系统的可扩展性、可用性、可观测性和可测试性，我做了比较大的重构
	1. 我重新设计了接口，提供了一个一致性抽象。（这里你可以补充你设计了哪些接口，然后强调一下效果）重构之后，研发效率提高了 30%，并且接入一个全新的第三方，也能对业务方做到完全没感知
	2. 我引入客户端治理措施，主要是限流和重试，并且针对一些特殊的第三方接口，我还设计了一些特殊的容错方案
	3. 我全方面接入了可观测性平台，包括 Prometheus 和 Skywalking，并且配置了告警。和原来比起来，现在能够做到快速响应故障了
	4. 我还进一步提供了测试工具，可以按照业务方的预期返回响应，比如说成功响应、失败响应以及模拟接口超时。针对压测，我也做了一些改进

![](image/Pasted%20image%2020250220235858.png)

注意，在介绍任何一点的时候都要强调一下你最终取得的效果。这样能够凸显你在改进系统的时候是有计划的、成体系的

另外这段话里面有一个地方你需要小心，就是研发效率提升 30%，这是我举例子说的，而现实中研发效率是很难衡量的。所以你可以换一种说法，用具体例子来说明研发效率的提高

- 在重构之前，原本我们公司的 A 组要接入我们的接口，搞了大概一个星期。后面重构之后，B 组接入我们的接口，只用了两天。而且稳定性更好，Bug 更少

类似地，在告警那里你也可以强调在你完成重构前后的对比

- 早期我们调用第三方接口的时候，缺乏监控和告警，以至于只有等用户出现问题联系客服的时候，或者业务方发现我们出现故障报告过来的时候，我们才知道出问题了。后面我们接入了监控和告警之后，在第三方接口出问题的短时间内，就能得到通知，然后快速启动各种容错预案，并且通知业务方和第三方

最后你要进一步总结和引导

- 在任何跟第三方打交道的场景之下，都要考虑好第三方崩溃的时候自己的系统怎么容错。公司或者部门内部的调用出现问题了，还可以推动同事快速修复。但是第三方是推不动的，所以只能是我们调用者考虑容错

这里我依旧是留了一个话柄，就等着面试官来问怎么容错，这也就是我在亮点方案里面写的前两点，你可以考虑选择其中符合你业务的来回答

### 亮点方案

这里我提供三个可以刷亮点的方向，分别是

- **同步转异步**
- **自动替换第三方**
- **压测支持**

你可以根据你的需要与面试的情况，选择其中一两个

#### 同步转异步

在一些不需要立刻拿到响应的场景，如果你发现第三方已经崩溃了，你可以将业务方的请求临时存储起来。等后面第三方恢复了再继续调用第三方处理

这种方案一般用于对时效性要求不高的业务。比如业务方只是要求你上报数据，不要求你立刻成功，那么你就可以采用这种方案

你可以仔细介绍你的容错方案，关键词就是**同步转异步**

![](image/Pasted%20image%2020250221000105.png)

- 正常来说我们推送数据都是尽可能实时推过去，但是有些时候业务方推过来的数据太多，又或者第三方崩溃，那么我就会临时将数据存起来。后面第三方恢复过来了，再逐步将数据同步过去。这算是比较典型的同步转异步用法

更进一步，你可以阐述对这个做法的进一步改进，关键词是**解耦**

- 我们这种容错机制其实完全可以做成利用消息队列来彻底解耦的形式。在这种解耦的架构下，业务方不再是同步调用一个接口，而是把消息丢到消息队列里面。然后我们的服务不断消费消息，调用第三方接口处理业务。等处理完毕再将响应通过消息队列通知业务

![](image/Pasted%20image%2020250221000506.png)

那么这种解耦的方式和直接调用的方式合并在一起，其实就是正常我们系统对接业务方的两个方案。所以你可以再次总结拔高一下

- 同步调用与异步解耦两种方式，可以看作是对接不同业务方的通用范式。一般而言但凡能异步解耦的，我绝不搞什么同步调用

#### 自动替换第三方

这种策略和我在负载均衡里面提到的有些类似，即调用一个第三方的接口失败的时候，你可以考虑换一个第三方

举例来说，你们公司有 A、B、C 三个短信供应商。现在你在选择使用 A 的时候，发现 A 一直返回失败的响应，或者说响应时间很长，那么你就可以考虑自动切换到 B 上

![](image/Pasted%20image%2020250221000608.png)

但是这种策略是受制于公司的情况的，大多数时候公司是没有这种可以切换的服务供应商的。早期我就听过某司使用的短信服务商服务异常，导致网站在一段时间内都无法发送验证码，引发了严重事故。所以你可以这样介绍你的方案，关键词是**自动替换**

- 为了进一步提高可用性，降低因为第三方故障引起事故的概率，我在调用第三方这里引入了自动替换机制。我们本来有多个第三方，相互之间是可以替换的，于是我就做了一个简单的自动切换机制。当我发现第三方接口出现故障的时候，就会切换到一个新的第三方

这里有一些面试官可能会追问的点

1. 你怎么知道第三方出问题了？这个问题可以参考我们前面讲过多次的判断服务健康与否的方式，比如说用响应时间、错误率、超时率。那么自然可以将话题引导到熔断、降级、限流那边
2. 如果全部可用的第三方都崩溃了怎么办？这种问题直接认怂就可以。因为一家出故障是小概率，多家同时出故障那就更是小概率事件了，在这种情况下你除了告警也没有别的办法了。也就是所谓的尽人事，听天命

#### 压测支持

每当你想搞压测的时候，你就会发现，所有的第三方接口都是压测路上的拦路虎

正常来说，你不能指望第三方会配合你的压测。你可以设想，类似于微信之类的开放平台是不可能配合你搞什么压力测试的。甚至即便你是非常强硬的甲方，你想让乙方配合你做压力测试，也是不现实的。所以你只能考虑通过 mock 来提供压测支持。和正常的测试支持比起来，压测你需要做到三件事

- 模拟第三方的响应时间
- 模拟触发你的容错机制。如果你采用了同步转异步这种容错机制，那么你需要确保在流量很大的情况下，你确实转异步了；如果你采用的是自动切换第三方，那你也要确保真的如同你设想的那样真的切换了新的第三方
- 流量分发。如果是在全链路压测的情况下，压测流量你会分发到 mock 逻辑，而真实业务请求你是真的调用第三方

![](image/Pasted%20image%2020250221001227.png)

那么你在介绍你的测试支持的时候可以强调一下这个特性

- 早期为了弄清楚服务的吞吐量和响应时间瓶颈，我搞过一些压测。但这些流量不能真的调用第三方，所以我为了解决压测这个问题，设计了两个东西
- 一个是模拟第三方的响应时间。不过这种模拟是比较简单的，就是在代码里面睡眠一段时间，这段时间是第三方接口的平均响应时间加上一个随机偏移量计算得出的。另一个是在并发非常高的情况下，会触发我的容错机制
- 而且我这里留好了接口，万一我们公司要做全链路压测了，我这边也可以根据链路元数据将压测流量转发到 mock 逻辑，而真实业务请求则会发起真实调用

最后一段我是假设你并没有实际接触过全链路压测。如果你接触过，那么你就可以改成“你已经做到”，而不是“留好了接口”。

### 总结

这节课我们讨论了调用第三方平台接口如何保证可用性的问题。当你和第三方平台打交道的时候，要做到这四点

- **一致性抽象**
- **客户端治理**
- **可观测性支持**
- **测试支持**

同时在后面我进一步提供了

- **同步转异步**
- **自动替换第三方**
- **压测支持**

三个亮点方案

你也可以看作是我们前面讲的熔断、限流、降级和超时控制在一个具体场景下的综合运用。不管你们公司用不用得上这些治理手段，你都要自己去尝试一下，因为面试需要你用上这些治理手段。不然你的整个项目经历平平无奇，那么连面试的机会都难得，更加不要说刷出亮点了

此外，在这节课还有一个点你需要额外注意，就是**强调自己对研发效率的改进**。研发效率是一个比较难量化的东西，所以你在面试的时候要想办法说服面试官相信你确实提高了研发效率

![](image/Pasted%20image%2020250221001603.png)
## 思考题

你们公司有没有出现什么因为第三方服务不可用引发的故障？后面你们有没有设计什么改进方案

- 一个手机短信验证码登录的功能，遇到过因为短信服务商故障，导致系统有一个小时不能通过短信验证码登录。后续的改进方案就是引入另外一家短信服务商，并加入切换机制
- 让我想到我们部门负责的短信服务，它就需要接入多个短信供应商，并且保证高可用，因此它做了接口的抽象，一个发短信的接口可以支持指定供应商，不指定则根据系统设置的权重加上触达率以及价格成本选择最合适当前业务的供应商进行发送，如果某个供应商一直不可用，检测到也会暂时下线它，又由于公司的营销业务经常需要发大量的短信，因此我们又实现了批量定时短信能力，服务自己本身也实现了限流，重试，同时为了节约成本配合业务组压测，增加一个调试模式，此模式不会真正发送短信，也做了很多的数据面板可以分析哪个供应商的性价比最高，错误率多少，错误分类占比等，然后回答下第一个问题，公司用到的第三方服务都是比较成熟的产品，所以极少出现问题，如果出问题了，那么数据补偿或者业务补偿机制可以搞一下，如果第三方可以替换，比如短信提供商，那就要支持重试后自动替换，当然，为了安抚客户，最好是用比较友好的报错提示，不要直接报服务端的错误给到用户

你的工作经历中有没有什么内容主要是提高同事研发效率的？如果有，你是怎么向面试官介绍这个项目并且让他相信你确实提高了研发效率的

- 做过一个流程引擎的功能。在企业软件开发中，流程审批是一个很常见的功能，流程也经常需要根据甲方要求做调整。在引入流程引擎前，都是靠代码来实现流程的流转，代码中充斥着条件判断，混杂了业务逻辑和流程处理逻辑，很难看懂也很难进行流程调整。后来我引入了一套流程引擎，把流程和业务完全剥离开，代码变得更清爽，流程调整也变容易了


# 综合服务治理方案

给你一个微服务应用，你怎么保证它的高可用

在面试互联网相关岗位的时候，大部分公司都会看重**高并发**、**高可用**和**大数据**相关的经验。不过有没有高并发和大数据的项目经验有点儿看命。因为如果你不是在大厂的核心部门，你是很难遇到真正的高并发和大数据场景的

高可用不一样，即便你维护的系统月活只有一万人，依旧可以把自己的系统做成高可用的所以相比之下，高可用就可以成为我们面试的主要发力点

![](image/Pasted%20image%2020250221002100.png)

当然你也需要意识到，一个类似淘宝那种量级的系统的高可用和一个简单的后台管理系统的高可用，含金量是不一样的。但还是那句话，又有几个人真的有机会接触到淘宝那种项目呢？所以如果你真的不知道怎么把自己平凡的项目说得比较有特色，那么就可以参考这节课的内容

## 介绍

一般衡量可用性，我们都是用SLA（Service Level Aggrement）指标，通常用 N 个九来说明。例如，当我们说微服务的可用性是三个九，是指系统在一段时间内（一般是一年）正常提供服务的时间超过了 99.9%

那么高可用究竟有多高？一般是指可用性需要达到三个九。当然有些人会认为需要达到四个九，这并没有硬性的标准。那么怎么做到高可用呢

核心有四点

- 容错
- 限制故障影响范围
- 出现故障可以快速发现，快速修复
- 规范变更流程

## 容错

容错是指不管发生了什么，你的系统都能正常提供服务，也就是所谓的 Design for Failure。用一句俗语来说，就是**凑合用**

![](image/Pasted%20image%2020250221160817.png)

系统中可能出问题的组件包括你的服务本身、你依赖的服务，还包括你依赖的硬件基础设施和软件基础设施

在面试的时候，最重要的是描述怎么保证自己的服务即便在遇到了一些故障的情况下，整个系统也能继续为用户提供服务

![](image/Pasted%20image%2020250221160858.png)

其次是软件基础设施如果出问题了，你是否能保证你的服务还能正常运作。如果你的服务不能正常运作，系统整体也要能运作，这主要考虑两个点

- 在公司内使用软件基础设施的高可用方案。比如说在使用 Redis 的时候就不再是使用单机 Redis，而是改成 Redis Cluster 或者直接使用云厂商的 Redis 服务
- 做好万一软件崩溃的容错手段。比如说前面我提到如果 Redis 崩溃了，你可以使用限流来保护数据库

剩余的内容除了依赖第三方这一个特殊的场景外，在面试中出现得很少，这里我们就不展开说了

容错的问题就是不管你怎么容错，最终都有可能出错，所以到了真出错的时候，你就要考虑限制故障影响范围

## 限制故障影响范围

限制故障影响范围是指万一真的出现了故障，也要尽可能减轻它的影响范围。影响范围可以从三个角度来考虑，尽可能使故障造成的业务损失更小、被影响的用户更少，还有被影响的其他组件更少

限制影响范围的最佳策略就是**隔离**。一个复杂的系统被划分成独立的不同的服务，服务内部再进一步细分模块、核心服务与非核心服务，尽量降低相互之间的影响

但是普遍来说，想要缩小影响范围总是面临两个难点

- **服务互相依赖**
	- 这种依赖一部分源自业务本身的复杂度，另外一部分则源自设计不合理。我们可以通过改进设计来降低服务之间的依赖，但是不可能做到彻底没有依赖。比如说后面提到的解耦方案，就是通过改进设计来降低服务之间依赖的一个例子
- **服务共享一部分基础设施**
	- 理论上只要你有足够多的钱，能够为每一个服务提供完全独立的基础设施，就可以彻底解决这个问题。但是实际中大部分公司连部署两套 Redis 都舍不得，所以我们经常听到某某公司因为共享基础设施导致系统崩溃的事故

![](image/Pasted%20image%2020250221161555.png)

在限制了故障影响范围后，你就要考虑快速发现和快速修复故障

## 快速发现和快速修复故障

快速发现强调的是**完备的观测和告警系统**。观测不仅要观测服务本身，也要对各种基础设施、第三方依赖进行观测。尤其是在你核心链路上依赖的东西，你都需要进行全方位地观测。有了观测之后，还要设置合理的告警，**没有告警的观测是没有灵魂的**

快速恢复则是尽可能减少服务不可用的时间。快速修复与其说是一个工程技术问题，不如说是一个组织建设问题。它实际上要求每一个组都需要安排人 24 小时值班，并且每个值班的人都需要了解整个组所维护的项目的细节，否则出了故障都没人响应，或者不知道怎么响应

![](image/Pasted%20image%2020250221161707.png)

所以要想真正做到快速修复，不能依赖于研发个人的自觉性，而是要依赖于自动处理故障的机制，后面我们再详细介绍这一机制

## 规范变更流程

规范变更流程是指任何一个人都不能随意发布新版本，也不能随意修改配置。任何一个变更都要经过 review，并且做好回退的准备

实际上，我们在实践中最害怕的就是发布新版本或者新配置。因为原本系统都运作得非常好，但是一旦上线新功能或者变更配置，就很容易出现线上故障。特别是有些时候因为急着修 Bug，根本没有测试就直接发布新代码或者配置，导致不仅已有的 Bug 没修好，还造成了新的问题

![](image/Pasted%20image%2020250221162211.png)

因此变更流程是一定要搞好的，搞好了变更流程，可用性就能大幅提升。不过这一点和快速修复一样，都是一个组织问题而不是一个工程技术问题

## 面试准备

在面试前，你需要准备一个**从前端到后端全方位的、完整的**高可用方案，而且要仔细思考其中的几个环节

- 所有面向前端用户的接口有没有限流之类的措施，防止攻击者伪造大量请求把你的系统搞崩
- 你所依赖的第三方组件，包括缓存（如 Redis）、数据库（如 MySQL）、消息队列（如 Kafka）是否启用了高可用方案
- 如果你依赖的某个第三方组件崩溃了，你维护的服务会发生什么事情，整个系统是否还能正常提供服务
- 你的所有服务是否选择了合适的负载均衡算法，是否有熔断、降级、限流和超时控制等治理措施
- 你所在公司的上线流程、配置变更流程等和研发息息相关的流程，或者说你认为会对系统可用性产生影响的各种流程

我在接下来的内容里给出了一个非常全面的高可用方案，你要做的就是根据你的真实项目经历来改造一下，并且重新组织一下语言

我在这里使用的都是一些比较普适的例子，也就是说即便你在中小企业也能用上这些例子。但是如果你在大厂，有机会接触到一些更加高级的高可用方案，此时你应该优先使用那些高级高可用方案。我建议你在面试前将整个内容写出来。面试讲究的是有备无患，千万别考验自己的临机应变能力

最佳的面试策略就是在自我介绍的时候提到自己在高可用微服务架构方面的经历，然后在介绍项目的时候，展示自己在入职之后大幅度提高了系统可用性的成果。之后面试官大概率会详细问你这个项目，以及你是怎么提高可用性的。这时候你就可以用到下面的话术了

### 基本思路

整个思路可以拆解成几个部分，分别是

- 发现问题
- 计划方案
- 落地实施
- 取得效果
- 后续改进

而且发现问题和取得效果这两个步骤可以通过前后对比来凸显你在这个过程中起到的作用

#### 发现问题

第一个部分发现问题由项目的核心困难、困难的具体体现、具体难点三个部分组成

- 某某业务是我们公司的核心业务，它的核心困难是需要保证高可用。在我刚入职的时候，这个系统的可用性还是比较低的。比如说我刚入职的第一个月就出了一个比较严重的线上故障，别的业务组突然上线了一个功能，带来了非常多的 Redis 大对象操作，以至于 Redis 响应非常慢，把我们的核心服务搞超时了
- 后面经过调研，我总结下来，系统可用性不高主要是这三个原因导致的
	1. 缺乏监控和告警，导致我们难以发现问题，难以定位问题，难以解决问题
	2. 缺乏服务治理，导致某一个服务出现故障的时候，整个系统都不可用了
	3. 缺乏合理的变更流程。我们每次复盘 Bug 时候，都觉得如果有更加合理的变更流程的话，那么大部分事故都是可以避免的

#### 计划方案

这里有一个常见的误区，就是你在现实中可能做过类似的事情，但是都是东一榔头西一棒槌，也就是说想到了啥就做啥。但是面试的时候，你一定要将这些内容组织得非常有条理、有计划

你要给面试官留下的印象不仅仅是你能解决问题，更是你能够有计划地解决问题。所以你一定要有一个非常清晰的、可执行性高的**计划**

- 针对这些具体的点，我的可用性改进计划分成了几个步骤
	1. 引入全方位的监控与告警，这一步是为了快速发现问题和定位问题
	2. 引入各种服务治理措施，这一步是为了提高服务本身的可用性，并且降低不同服务相互之间的影响
	3. 为所有第三方依赖引入高可用方案，这一步是为了提高第三方依赖的可用性
	4. 拆分核心业务与非核心业务的共同依赖。这一步是为了进一步提高核心业务的可用性
	5. 规范变更流程，降低因为变更而引入 Bug 的可能性

![](image/Pasted%20image%2020250221162840.png)

如果你们公司有非常完善的基础设施和强大的技术实力，那么你可以加上像全链路压测、混沌工程、故障演练等高端方案，作为你整个计划中的一部分

#### 落地实施

然后你再讲落地实施。落地实施的时候你要补充细节，同时也可以掺杂一些落地过程中的痛点

- 在第一个步骤里面，就监控来说，既要为业务服务添加监控和告警，又要为第三方依赖增加监控，比如说监控数据库、Redis 和消息队列。而告警则要综合考虑告警频率、告警方式以及告警信息的内容是否足够充足，减少误报和谎报。本身这个东西并不是很难，就是非常琐碎，要一个个链路捋过去，一个个业务查漏补缺
- 就第二个步骤来说，服务治理包括的范围比较广，我使用过的方案也比较多，比如说限流熔断等等
- 第三个步骤遇到了比较大的阻力，主要是大部分第三方依赖的高可用方案都需要资金投入。比如说最开始我们使用的 Redis 就是一个单机 Redis，那么后面我尝试引入 Redis Cluster 的时候，就需要部署更多的实例
- 第四个步骤也是执行得不彻底。现在的策略就是新的核心业务会启用新的第三方依赖集群，比如说 Redis 集群，但是老的核心业务就保持不动

你可能发现了，我在上面的回答中，谈到第三点和第四点的时候都说执行得不太好。这会不会给面试官留下不好的印象呢

其实不会。因为我陈述的基本上都是事实，这些困难都是实打实的，而且也是面试官能理解的。另一方面，一个方案不可能十全十美，适当地暴露一些问题能够增强说服力

第五个步骤有点特殊，取决于你在公司的地位。如果你在公司很有话语权，甚至本身就在带团队，那么你可以直接说你推行了新的变更流程。如果你是一个纯粹的“搬砖”工程师，那么可以参考这个回答，关键词是**建议**

- 第五个步骤是我在公司站稳脚跟之后跟领导建议过几次，后来领导就制定了新的规范，主要是上线规范，包括上线流程、回滚计划等内容

#### 取得效果

既然我们这里讨论的是可用性，那么你取得的效果肯定就是可用性方面有多大的改进。一般来说，我建议你说可用性达到了**三个九**，而不是四个九，毕竟四个九的可用性有点过于夸张

- 经过我的改进之后，现在我维护的服务的可用性从原来不足两个九提升到了三个九

你也可以比较幽默地回答

- 现在 Bug 数量也减少了。Bug 复盘的时候我已经不再是那个挨骂的人了，变成了看别人挨骂的人

同时你还可以强调一下，系统中超出你影响力范围的部分，可用性还是比较差

- 不过我的服务还依赖于一些同事提供的服务，而他们的服务可用性就还是比较差。我这边只能是说尽量做到容错，比如说提供有损服务。后面要想进一步提高可用性，还是得推动同事去提高可用性

如果面试官质疑你为什么三个九也敢说是高可用，你要怎么回答呢

其实不用慌，你可以解释一下，也可以理解为认怂，关键词是**影响力有限**

- 我也一直在想办法进一步提高可用性，但是整个系统要做到四个九还是非常难的，需要整个公司技术人员一起努力才能达到。我在公司的影响力还局限在我们部门，困难比较多，暂时做不到那么高的可用

#### 后续改进

最后你要补充一下你的改进计划。一般来说，改进计划都是针对已有方案的缺点，所以你要先讲已有方案的缺点

- 目前我的服务，尤其是一些老服务，相互之间还是在共享一些基础设施。一个出问题就很容易牵连其他服务，所以我还需要进一步将这些老服务解耦

然后你可以再举一个非常具体的改进措施，来增强说服力

- 比如说，我一定要让我的全部服务都使用我自己所在组的数据库实例，省得因为别组的同事搞崩了数据库，牵连到我的业务。大家一起用一个东西，出了事别人死不认账，甩锅都甩不出去

讲改进方案有一个好处，就是它还没实施，你就可以随便讲，什么高大上你就讲什么

### 亮点方案

掌握了面试的基本思路之后，实际上你在这次面试中就基本上能给面试官留下一个不错的印象了。这里我再额外补充一些方案，你可以选择其中一两个来进一步强化你在面试官心目中的形象

#### 异步 / 解耦

这个方案适用于什么情况呢？就是你的某一个业务可以分成两部分。一部分是必须要同步执行成功的关键步骤，另外一部分则是可以异步执行的非关键步骤

比如说在一个简单的创建订单的场景中，创建订单、支付是必须要同步执行成功的。但是另外一些部分，比如说发邮件通知你下单成功、为你增加积分这种就不是一定要立刻执行成功的

![](image/Pasted%20image%2020250221174155.png)

因此在设计高可用微服务的时候有一个技巧或者说原则，就是能够异步执行的绝对异步执行，能够解耦的必须解耦

这种理念用一句话来形容就是**多做多错，少做少错，不做不错**

因此你可以用这个话术来介绍你的方案，关键词是**异步 / 解耦**

- 我还全面推行了异步 / 解耦。我将核心业务的逻辑一个个捋过去，再找产品经理确认，最终将所有的核心业务中能够异步执行的都异步执行，能够解耦的都解耦。这样在我的业务里面，需要同步执行的步骤就大大减少了。而后续异步执行的动作，即便失败了也可以引入重试机制，所以整个可用性都大幅度提升了
- 比如说在某个场景下，整个逻辑可以分成很明显的两部分，必须要同步执行的 A 步骤和可以异步执行的 B 步骤。那么在 A 步骤成功之后，再发一条消息到消息队列。另外一边消费消息，执行 B 步骤

#### 自动故障处理

严格来说，熔断、限流和降级也算是自动故障处理。不过我这里说的是有一个独立的系统来处理业务系统发生的故障

![](image/Pasted%20image%2020250221174319.png)

一个问题从发现到找出临时应对方案、再到付诸实施，一不留神一个小时就过去了。所以在达成三个九以后，如果你还想进一步提升可用性，那就要么降低出事故的概率，要么提高反应速度

人本身做不到长时间精神紧绷 24 小时待命，并且同一个项目组的项目也很难说了如指掌，所以自动故障处理机制的重要性不言而喻。甚至可以说，如果没有自动故障处理机制，是不可能达到四个九的可用性的

这里我给你一个例子：微服务集群自动扩容。它是指对整个微服务集群进行监控，如果发现集群负载过高那么就会自动扩容

![](image/Pasted%20image%2020250221174818.png)

所以你可以这么回答，关键词是**自动扩容**

- 为了进一步提高整个集群服务的可用性，我跟运维团队进行密切合作，让他们支持了自动扩容。整个设计方案是允许不同的业务方设置不同的扩容条件，满足条件之后运维就会自动扩容。比如说我为我的服务设置了 CPU 90% 的指标。如果我这个服务所有节点的 CPU 使用率都已经超过了 90%，并且持续了一段时间，那么就会触发自动扩容，每次扩容会新增一个节点

这里我用的例子比较简单，决策的理由也比较简单

- CPU 使用率长期处于高位，基本上代表节点处于高负载状态。并且我强调的是集群里面的节点都超过了这个指标，防止单一节点超过该指标之后引起不必要的扩容。比如说，万一某个节点非常不幸，处理的都是复杂的请求，那么它就会处于高负载的状态，但是其他节点其实负载还很低。那么这个时候扩容，并没有什么效果

还有一些常见的方案，你可以参考

- 自动修复数据，最常见的就是有一个定时任务比对不同的业务数据，如果数据不一致，就会发出告警，同时触发自动修复动作
- 自动补发消息，也是通过定时任务等机制来比对业务数据，如果发现某条消息还没发，就会触发告警，同时触发补发消息动作

但凡你的业务有很多需要人手工介入处理的数据问题，你都可以考虑设计一个自动恢复程序，去自动地发现和修复不一致的数据

### 总结

我要强调一下，这里给出的整个话术和方案，你要根据你的实际经验来做调整。业界有非常多的高可用方案，你可以多学几个，纳入你的面试方案里面

你不需要掌握全部的高可用方案，因为实在太多学不过来。你只需要重点掌握几种，然后在面试的时候注重引导和把控面试节奏，将面试内容限制在你所了解的那几种上就可以

![](image/Pasted%20image%2020250221174950.png)

## 思考题

四个九代表全年不可用时间不超过 53 分钟，那么你知道三个九和五个九又各自代表多少时间吗？从你个人经历出发，你认为四个九的可用性，究竟难不难达成？

- 3个9代表8.76小时，4个9代表52.6分钟，5个9代表5.26分钟。我自己做过高可用的系统，在我的系统里可用性是3个9到4个9之间接近4个9，从我的实际落地看，要达到4个9还是很有挑战的，不可用的来源主要是几个方面：程序bug、线上变更失误或方案考虑不周、机器宕机、网络故障、机房故障，前两个属于人为，后几个属于非人为，理论上说，非人为不可用自动恢复的速度是比较快的，只要机器网络不是特别烂，4个9比较容易达成，但前提是没有人为引起不可用，可实际这是很难的

除了我这里提到的各种措施以外，你自己有没有做过其他提高可用性的事情？你怎么把它整合进你的面试方案里面？

- 回滚方案，机房自动切换，异地多活，规范流程（虽然文中提到了，但是还是想说，太重要了）都是卡在人这一个环节里面，机器能解决的问题都好解决
